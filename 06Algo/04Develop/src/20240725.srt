1
00:00:00,450 --> 00:00:02,333
内容/录制:Z0MI酱 视频剪辑/字幕:梁嘉铭

2
00:00:05,650 --> 00:00:06,450
哈喽大家好

3
00:00:06,450 --> 00:00:08,166
大家都说时间就是金钱

4
00:00:08,166 --> 00:00:11,000
那我最近时间有点紧的ZOMI

5
00:00:11,200 --> 00:00:13,250
今天我们跟大家来去唠一唠

6
00:00:13,250 --> 00:00:15,566
大模型的一个开源跟闭源的情况

7
00:00:15,566 --> 00:00:18,366
看看哪家大模型比较强

8
00:00:18,400 --> 00:00:19,966
在这个话题

9
00:00:19,966 --> 00:00:21,483
主要是前几天

10
00:00:21,483 --> 00:00:22,766
也就7月23号

11
00:00:22,966 --> 00:00:24,283
Llama3.1公布了

12
00:00:24,283 --> 00:00:25,400
说了它的性能

13
00:00:25,400 --> 00:00:28,250
能够媲美GPT4和Cloude3.5

14
00:00:28,250 --> 00:00:30,000
确实从下面的很多的测评

15
00:00:30,000 --> 00:00:31,566
还有它的数据报告来看

16
00:00:31,566 --> 00:00:34,933
Llama3.1的这个开源全世界最大的

17
00:00:34,933 --> 00:00:36,883
参数量最夸张的大模型

18
00:00:37,050 --> 00:00:38,883
效果确实非常的好

19
00:00:38,883 --> 00:00:40,600
那这个事情或者这个事标

20
00:00:40,600 --> 00:00:42,766
就标志着整个大模型的开展

21
00:00:42,766 --> 00:00:43,933
或者大模型的发展

22
00:00:43,933 --> 00:00:46,566
已经进入到了一个新的进程了

23
00:00:46,566 --> 00:00:48,883
那在今天或者这一期视频

24
00:00:48,883 --> 00:00:50,733
我们主要是聊聊几个类

25
00:00:51,250 --> 00:00:52,483
首先第一个内容

26
00:00:52,483 --> 00:00:55,883
我们来聊聊最近出圈的李校长

27
00:00:55,883 --> 00:00:57,283
李彦宏老师

28
00:00:57,333 --> 00:00:57,800
那第二个

29
00:00:57,800 --> 00:00:58,733
我们去看一下

30
00:00:58,733 --> 00:01:01,050
整个大模型的性能的分析

31
00:01:01,050 --> 00:01:03,083
包括开源的大模型和闭源的大模型

32
00:01:03,166 --> 00:01:04,450
了解完大模型的性能了

33
00:01:04,450 --> 00:01:05,366
我们回顾一下

34
00:01:05,366 --> 00:01:07,133
可能最近这几个月

35
00:01:07,366 --> 00:01:09,400
整个大模型都在降价

36
00:01:09,400 --> 00:01:11,166
大模型降价潮的问题

37
00:01:11,166 --> 00:01:11,933
接着我们看一下

38
00:01:11,933 --> 00:01:13,533
整个大模型的具体的发展

39
00:01:13,533 --> 00:01:15,733
特别是开源的Llama引导了国内

40
00:01:15,733 --> 00:01:17,533
说实话国内大部分的大模型

41
00:01:17,533 --> 00:01:18,933
或者都是参考Llama

42
00:01:18,933 --> 00:01:20,133
或者借鉴Llama的

43
00:01:20,133 --> 00:01:21,200
那了解完这些之后

44
00:01:21,200 --> 00:01:21,733
我们看一下

45
00:01:21,733 --> 00:01:23,600
大模型的技术的发展的趋势

46
00:01:23,600 --> 00:01:25,566
和相关的思考的点

47
00:01:25,566 --> 00:01:25,933
第一个

48
00:01:25,933 --> 00:01:29,283
就是MOE的结构到底往哪个方向去演进

49
00:01:29,283 --> 00:01:30,766
长序列稀疏万亿

50
00:01:30,766 --> 00:01:33,250
那最后我们还是要真正的去看一下

51
00:01:33,250 --> 00:01:34,966
为什么Mate这么大方

52
00:01:34,966 --> 00:01:36,533
开源了一个世界最大

53
00:01:36,533 --> 00:01:41,050
而且效果最好的开源大模型

54
00:01:41,050 --> 00:01:44,483
我们马上进入下面的真正的内容

55
00:01:46,050 --> 00:01:48,333
第一个内容就是李校长

56
00:01:48,333 --> 00:01:49,083
最近或者

57
00:01:49,083 --> 00:01:50,366
一个月前的WAIC

58
00:01:50,366 --> 00:01:53,283
李校长真的是惊句频出

59
00:01:53,450 --> 00:01:55,400
我们在大模型这个领域里面

60
00:01:55,400 --> 00:01:57,450
被收了智商税了吗

61
00:01:57,450 --> 00:01:59,883
那下面我们看一下具体的这个链接

62
00:01:59,883 --> 00:02:01,483
看一下这里面的李校长

63
00:02:01,483 --> 00:02:02,966
在WAIC期间

64
00:02:02,966 --> 00:02:06,000
讲了哪些内容

65
00:02:06,000 --> 00:02:07,283
各位下游好

66
00:02:07,600 --> 00:02:08,483
非常高兴

67
00:02:08,483 --> 00:02:11,766
再次来到上海参加世界人工智能大会

68
00:02:12,050 --> 00:02:12,883
大家可以看到

69
00:02:12,883 --> 00:02:15,566
国内已经有多款闭源模型

70
00:02:15,566 --> 00:02:18,883
声称他们已经追平

71
00:02:18,966 --> 00:02:21,850
或者是超越了GPT4的水平

72
00:02:21,850 --> 00:02:24,250
注意我这说的是必源的大模型

73
00:02:24,250 --> 00:02:25,600
不是开源大模型

74
00:02:26,366 --> 00:02:27,250
同样参数必然性能力

75
00:02:27,250 --> 00:02:28,050
就是开源模型要更好

76
00:02:28,050 --> 00:02:29,166
而如果开源想要能力追平必源

77
00:02:29,166 --> 00:02:29,966
Llama它就需要更大参数

78
00:02:29,966 --> 00:02:31,050
这就对于成本更高

79
00:02:31,050 --> 00:02:31,850
反应速度更慢

80
00:02:31,850 --> 00:02:33,000
很多人把开源模型改款也这样

81
00:02:33,000 --> 00:02:34,133
可以更好的服务自己的个性化应用

82
00:02:34,200 --> 00:02:34,400
殊不知

83
00:02:34,400 --> 00:02:35,483
这样就创造一个固本的模型

84
00:02:35,483 --> 00:02:36,933
既无法从基础模型去升级

85
00:02:37,000 --> 00:02:38,200
也没办法跟别人去共享专利

86
00:02:38,566 --> 00:02:39,133
当然了我也承认

87
00:02:39,133 --> 00:02:39,933
开源模型在某些场景下

88
00:02:39,933 --> 00:02:40,600
是有它的价值的

89
00:02:40,600 --> 00:02:41,800
比如说一些学术研究或者在教学领域

90
00:02:41,800 --> 00:02:42,766
大家想研究党性的工作机制

91
00:02:42,766 --> 00:02:43,850
形成理论能配受更有价值的

92
00:02:43,850 --> 00:02:44,450
因为大家可能也想听到

93
00:02:44,450 --> 00:02:45,333
就是我们觉得他们的能力很强

94
00:02:45,333 --> 00:02:45,933
但是不知道为什么这么强

95
00:02:45,933 --> 00:02:46,733
你背后没有理论的支撑

96
00:02:46,733 --> 00:02:47,650
最严重的东西用开远了

97
00:02:47,650 --> 00:02:48,166
我觉得没有用

98
00:02:48,166 --> 00:02:49,733
但是大多数用场景开源模型并不合适

99
00:02:49,800 --> 00:02:49,966
当你处于

100
00:02:49,966 --> 00:02:50,800
一个激烈竞争的市场环境当中

101
00:02:50,800 --> 00:02:51,966
的时候你需要让自己的业务

102
00:02:51,966 --> 00:02:52,966
效率比你的同行更高

103
00:02:52,966 --> 00:02:53,850
成本比同行更低

104
00:02:53,850 --> 00:02:55,400
这时候商业化利润模型那是最难的

105
00:02:56,133 --> 00:02:57,533
看完刚才那个视频之后

106
00:02:57,533 --> 00:02:59,133
我们现在在录了一些

107
00:02:59,133 --> 00:03:01,283
网上对WAIC圆桌访谈的

108
00:03:01,283 --> 00:03:01,850
一个具体

109
00:03:01,850 --> 00:03:03,800
关于李校长相关的一个语录

110
00:03:03,800 --> 00:03:04,850
那语录里面

111
00:03:05,000 --> 00:03:05,733
李校长

112
00:03:05,733 --> 00:03:08,133
就认为开源实际上是一种智商税

113
00:03:08,333 --> 00:03:09,000
那这个时候

114
00:03:09,000 --> 00:03:10,800
可能还会有一些相关的论调

115
00:03:10,800 --> 00:03:11,650
但是这一句话

116
00:03:11,650 --> 00:03:13,933
已经被业界已经无限的放大了

117
00:03:13,933 --> 00:03:15,683
那我们看一下它里面的主要的论调

118
00:03:15,683 --> 00:03:17,083
就是如果我们理性的去想

119
00:03:17,083 --> 00:03:19,366
大模型能够带来什么价值

120
00:03:19,766 --> 00:03:21,733
以及什么样的成本的价值的时候

121
00:03:21,733 --> 00:03:22,533
你就会发现

122
00:03:22,533 --> 00:03:25,733
我们应该永远选择闭源的模型

123
00:03:25,733 --> 00:03:28,450
那这样就是李彦宏老师认为的

124
00:03:28,450 --> 00:03:31,566
那无论今天的Chatgpt还好

125
00:03:31,566 --> 00:03:32,650
文心一言大模型

126
00:03:32,766 --> 00:03:35,133
一定会比开源的大模型更强哦

127
00:03:35,250 --> 00:03:36,933
推理的成本更低哦

128
00:03:37,200 --> 00:03:39,766
你要相信开源是骗你的

129
00:03:39,800 --> 00:03:42,133
闭源才是永远真正的选择

130
00:03:43,000 --> 00:03:45,250
那这个就是彦宏老师说的话

131
00:03:45,250 --> 00:03:47,050
当然他有很多的内容

132
00:03:47,050 --> 00:03:47,850
例ToB端

133
00:03:47,850 --> 00:03:49,000
我们一定要选择一个

134
00:03:49,000 --> 00:03:50,683
性价比最好的模型哦

135
00:03:50,683 --> 00:03:51,883
那这个最好的模型

136
00:03:51,883 --> 00:03:53,850
就是我们的闭源的文心一言

137
00:03:53,850 --> 00:03:55,366
哈哈那另外的话

138
00:03:55,366 --> 00:03:57,250
他还说那个闭源的大模型

139
00:03:57,250 --> 00:04:00,000
它有一个开源的模型不具备的优势

140
00:04:00,083 --> 00:04:03,133
那这个相对来说规模更小的模型

141
00:04:03,250 --> 00:04:04,566
都是从那些最大

142
00:04:04,566 --> 00:04:06,933
最powerful的模型里面裁剪出来的

143
00:04:07,333 --> 00:04:09,883
裁剪出来的这些更小规模的模型

144
00:04:09,933 --> 00:04:13,166
你要比那些同等规模的开源的模型

145
00:04:13,166 --> 00:04:14,366
效果要更好

146
00:04:14,483 --> 00:04:15,400
反正就是

147
00:04:15,400 --> 00:04:17,483
你要相信闭源大模型

148
00:04:17,483 --> 00:04:19,333
不要相信开源大模型

149
00:04:19,483 --> 00:04:21,450
那这些就是李彦宏老师里面说的

150
00:04:21,450 --> 00:04:22,766
开源就是一种智商税

151
00:04:22,766 --> 00:04:24,283
相关的一个论调了

152
00:04:24,283 --> 00:04:24,800
那就是

153
00:04:24,800 --> 00:04:25,966
我们回顾一下

154
00:04:25,966 --> 00:04:29,166
实际上这已经不是第一次李校长了

155
00:04:29,166 --> 00:04:31,166
和李校长口出惊句了

156
00:04:31,166 --> 00:04:32,450
在2024年的时候

157
00:04:32,450 --> 00:04:33,283
4月份

158
00:04:33,400 --> 00:04:34,000
李校长

159
00:04:34,000 --> 00:04:36,083
就已经提出过或者做了一个预言

160
00:04:36,083 --> 00:04:38,283
开源大模型肯定会越来越落后的

161
00:04:38,283 --> 00:04:39,766
没想到四个月之后

162
00:04:39,800 --> 00:04:40,733
这个现象

163
00:04:40,733 --> 00:04:42,933
大家看到Llama3.1的发布之后

164
00:04:42,933 --> 00:04:43,733
都已经知道了

165
00:04:43,733 --> 00:04:44,883
还有DISC的发布

166
00:04:44,883 --> 00:04:46,933
这句论调是正确和错

167
00:04:46,933 --> 00:04:48,483
大家来去评判一下

168
00:04:48,600 --> 00:04:51,483
而我们最近的网红红衣大叔

169
00:04:51,483 --> 00:04:54,250
里面就在发反对的声音了

170
00:04:54,250 --> 00:04:55,483
就好像类比了一个

171
00:04:55,483 --> 00:04:56,683
如果没有开源的文化

172
00:04:56,683 --> 00:04:57,766
就不会有Linus拍照

173
00:04:57,766 --> 00:05:00,083
这种非常牛逼的工具

174
00:05:00,650 --> 00:05:01,133
所以说

175
00:05:01,133 --> 00:05:03,850
我们这些围观群众或者吃瓜群众

176
00:05:03,850 --> 00:05:06,333
简单看看大了的论调就好了

177
00:05:06,333 --> 00:05:09,683
然后等待时间去验证真正的内容

178
00:05:09,883 --> 00:05:11,850
同期Llama3.1发布之后

179
00:05:11,850 --> 00:05:13,083
Mate的CEO

180
00:05:13,083 --> 00:05:15,200
马克扎克伯格

181
00:05:15,200 --> 00:05:17,200
这个英文我也不知道怎么读了

182
00:05:17,650 --> 00:05:19,533
自己就亲自撰写了一篇文章

183
00:05:19,533 --> 00:05:22,050
叫做open source AI is the path forward

184
00:05:22,166 --> 00:05:23,450
那这一篇文章

185
00:05:23,450 --> 00:05:26,366
也是希望大家能够真正的去看一看

186
00:05:26,366 --> 00:05:28,250
那热门的链接也给出来了

187
00:05:28,250 --> 00:05:29,850
大家也可以下载这个PPT

188
00:05:30,000 --> 00:05:31,883
你们去打开看一下相关的内容

189
00:05:32,133 --> 00:05:34,000
里面就对开源的大模型

190
00:05:34,000 --> 00:05:37,000
Meta对全球的一个AI发展的重要性

191
00:05:37,000 --> 00:05:38,766
的论调而且预测了今年年底

192
00:05:38,766 --> 00:05:39,933
Meta的一个AI

193
00:05:39,933 --> 00:05:41,400
肯定会超过Chatgpt

194
00:05:41,450 --> 00:05:44,200
成为最广泛的AI大模型的助手

195
00:05:44,200 --> 00:05:45,050
那同时候

196
00:05:45,050 --> 00:05:47,050
也有很多业界的一些大佬

197
00:05:47,050 --> 00:05:48,933
包括我们的杨乐春老师

198
00:05:48,933 --> 00:05:50,400
还有我们的Angrew ng

199
00:05:50,650 --> 00:05:52,000
我也不知道为什么

200
00:05:52,000 --> 00:05:53,800
一个外国人起了个中文名

201
00:05:53,883 --> 00:05:54,650
一个中国人

202
00:05:54,650 --> 00:05:55,600
或者一个华人

203
00:05:55,600 --> 00:05:57,083
起了一个英文名

204
00:05:57,083 --> 00:05:57,733
那这里面

205
00:05:57,733 --> 00:05:58,933
先不吐槽了

206
00:05:59,250 --> 00:06:00,000
两位大佬了

207
00:06:00,000 --> 00:06:02,883
都在说Llama3.1真牛逼

208
00:06:03,250 --> 00:06:04,850
Llama3.1很帅

209
00:06:04,850 --> 00:06:06,766
很有用很霸气

210
00:06:06,766 --> 00:06:07,866
还开源

211
00:06:07,866 --> 00:06:08,966
那因此

212
00:06:08,966 --> 00:06:09,566
我们可以看到

213
00:06:09,566 --> 00:06:10,166
Llama3.1

214
00:06:10,166 --> 00:06:12,933
确实引起了我们今天的这个话题哦

215
00:06:13,283 --> 00:06:15,400
也啪啪啪的打脸了李校长

216
00:06:15,450 --> 00:06:17,366
为什么啪啪啪的打脸李校长

217
00:06:17,366 --> 00:06:18,533
因为大家都知道

218
00:06:18,533 --> 00:06:21,333
百度是AI界的黄埔军校

219
00:06:21,333 --> 00:06:23,650
因此我们称李彦宏为李校长

220
00:06:23,650 --> 00:06:25,050
一点都不为过

221
00:06:27,166 --> 00:06:28,333
好了吐槽完之后

222
00:06:28,333 --> 00:06:30,050
我们还是回归一些正经的内容

223
00:06:30,050 --> 00:06:30,450
第二个

224
00:06:30,450 --> 00:06:31,133
我们就看一下

225
00:06:31,133 --> 00:06:33,366
模型的性能的相关的分析

226
00:06:33,366 --> 00:06:34,933
说实话Llama出来之后

227
00:06:34,933 --> 00:06:36,000
整体我们可以看到

228
00:06:36,000 --> 00:06:37,333
网络模型的规模

229
00:06:37,333 --> 00:06:38,566
越做越大

230
00:06:39,000 --> 00:06:39,933
是另外一个方向了

231
00:06:39,933 --> 00:06:41,083
当然我们还有另外一个方向

232
00:06:41,083 --> 00:06:43,933
就是网络的模型肯定是越来越小

233
00:06:43,933 --> 00:06:45,933
就做一个大规模的大模型

234
00:06:45,933 --> 00:06:47,050
效果越来越好

235
00:06:47,050 --> 00:06:48,650
然后蒸馏出一些小模型

236
00:06:48,650 --> 00:06:49,250
那小模型

237
00:06:49,250 --> 00:06:51,166
就是针对我们的大规模小模型

238
00:06:51,166 --> 00:06:52,683
在端侧真正的应用的

239
00:06:52,683 --> 00:06:54,566
可以看到现在整体的效果

240
00:06:54,766 --> 00:06:55,366
你可以看到

241
00:06:55,366 --> 00:06:56,733
上面红色的这条线

242
00:06:56,733 --> 00:06:58,600
就是闭源的大模型

243
00:06:58,600 --> 00:07:00,400
确实闭源的大模型的效果

244
00:07:00,400 --> 00:07:01,450
一直都在线

245
00:07:01,450 --> 00:07:02,650
永远的或者一直

246
00:07:02,650 --> 00:07:04,050
在一定的时间内

247
00:07:04,166 --> 00:07:07,083
是超越下面绿色的这条线的

248
00:07:07,083 --> 00:07:08,683
那可以看到未来

249
00:07:08,966 --> 00:07:10,133
那再从未来的方向

250
00:07:10,133 --> 00:07:11,450
已经可以看到未来

251
00:07:11,450 --> 00:07:12,733
不管是闭源还是开源

252
00:07:12,733 --> 00:07:13,283
大模型

253
00:07:13,283 --> 00:07:14,883
也是慢慢的走向了一个

254
00:07:14,883 --> 00:07:16,800
相同的精度的情况

255
00:07:16,800 --> 00:07:17,566
所以可以看到

256
00:07:17,566 --> 00:07:19,083
开源大模型跟闭源大模型

257
00:07:19,083 --> 00:07:20,800
已经开始追平了

258
00:07:21,483 --> 00:07:22,400
在了解闭源大模型

259
00:07:22,400 --> 00:07:23,533
开源大模型的时候

260
00:07:23,533 --> 00:07:25,483
客户或者引起一些国内的开源

261
00:07:25,483 --> 00:07:27,483
闭源大模型的一些支撑工作的时候

262
00:07:27,483 --> 00:07:29,200
ZOMI就聊聊我的本职工作了

263
00:07:29,200 --> 00:07:29,483
说实话

264
00:07:29,483 --> 00:07:31,800
我是大模型的并行加速库的专家

265
00:07:31,800 --> 00:07:32,850
训练解决放入架构师

266
00:07:32,850 --> 00:07:35,850
或者叫做大模型的训练架构师都行

267
00:07:35,850 --> 00:07:36,966
不管你怎么叫

268
00:07:37,083 --> 00:07:37,566
实际上

269
00:07:37,566 --> 00:07:39,600
ZOMI就是这样

270
00:07:39,850 --> 00:07:41,850
就是辛苦的去打打代码

271
00:07:41,850 --> 00:07:42,650
做做方案

272
00:07:42,683 --> 00:07:44,283
那在华为昇腾里面

273
00:07:44,283 --> 00:07:45,533
主要是给各大厂商

274
00:07:45,533 --> 00:07:47,083
做一些相关的技术支持了

275
00:07:47,083 --> 00:07:49,083
相关的一些工作了

276
00:07:49,083 --> 00:07:49,850
那所以

277
00:07:49,850 --> 00:07:51,683
我们会在这次工作

278
00:07:51,683 --> 00:07:52,166
就发现

279
00:07:52,166 --> 00:07:54,650
其实大家使用最多的开源大模型

280
00:07:54,650 --> 00:07:56,200
其现在主要集中在三个

281
00:07:56,200 --> 00:07:58,000
第一个是DeepSeek V2

282
00:07:58,000 --> 00:08:01,133
也是幻方科技推出的一个大模型

283
00:08:01,250 --> 00:08:03,000
这个大模型使用了MOE的架构

284
00:08:03,000 --> 00:08:05,483
模型的尺寸也会非常大 236B

285
00:08:05,483 --> 00:08:07,083
那激活参数是21B

286
00:08:07,083 --> 00:08:09,483
同样的上下文的支持也是非常长的

287
00:08:09,483 --> 00:08:11,400
第二这个就是千问2.5了

288
00:08:11,400 --> 00:08:12,766
阿里的开源的大模型

289
00:08:12,766 --> 00:08:13,766
那千问2.5了

290
00:08:13,766 --> 00:08:15,333
说实话他已经发布了五个

291
00:08:15,333 --> 00:08:16,733
不同的尺寸的版本了

292
00:08:16,733 --> 00:08:17,766
而且训练的数据

293
00:08:17,766 --> 00:08:20,283
是在32K里面去做一个训练的

294
00:08:20,283 --> 00:08:22,133
真正外推或者推理的时候

295
00:08:22,133 --> 00:08:24,050
实现了128K的长序列

296
00:08:24,083 --> 00:08:25,366
另外第三个

297
00:08:25,650 --> 00:08:27,400
就是Llama3.1

298
00:08:27,400 --> 00:08:29,333
最近发布的开源大模型

299
00:08:29,333 --> 00:08:30,566
我相信很多人都会跟进

300
00:08:30,566 --> 00:08:32,050
因为Llama的123了

301
00:08:32,050 --> 00:08:34,166
已经有非常多的国内的厂商

302
00:08:34,166 --> 00:08:35,683
或者国内的大模型厂商了

303
00:08:35,883 --> 00:08:37,366
都在相关的跟进

304
00:08:37,366 --> 00:08:39,650
这里面就推出了一个微调后SFT

305
00:08:39,650 --> 00:08:42,050
和DPO相关的一个对齐的方式

306
00:08:42,050 --> 00:08:44,366
而且也支持常上下文的一个

307
00:08:44,366 --> 00:08:45,850
还有多模态的相关的能力

308
00:08:45,850 --> 00:08:47,566
那接下来我们逐个的模型打开

309
00:08:47,566 --> 00:08:48,883
看一下它们的性能哦

310
00:08:49,250 --> 00:08:50,050
首先第一个

311
00:08:50,050 --> 00:08:52,650
就是DeepSeek幻方的一个具体的性能

312
00:08:52,650 --> 00:08:54,166
说实话DeepSeek它整体的performance

313
00:08:54,166 --> 00:08:56,650
特别是在MMLU里面的个测评情况下

314
00:08:56,650 --> 00:08:58,650
它的性能还是非常的好的

315
00:08:58,650 --> 00:09:00,566
而且我们往右边的这个图看看

316
00:09:00,566 --> 00:09:02,166
整个DeepSeek Compare With Other

317
00:09:02,166 --> 00:09:04,850
也就是其他的闭源和开源的大模型

318
00:09:04,850 --> 00:09:05,850
整个幻方了

319
00:09:05,850 --> 00:09:07,450
它的一个整体的效果

320
00:09:07,450 --> 00:09:10,400
说实话也是非常的优秀的

321
00:09:10,933 --> 00:09:11,566
了解完看法之后

322
00:09:11,566 --> 00:09:13,200
我们看一下另外一个开源大模型

323
00:09:13,200 --> 00:09:14,333
千问二点多

324
00:09:14,333 --> 00:09:15,000
整个千问的

325
00:09:15,000 --> 00:09:16,333
说实话他不比

326
00:09:16,333 --> 00:09:17,533
或者他不用GPT来比

327
00:09:17,533 --> 00:09:19,400
因为确实跟GPT还是有点差距的

328
00:09:19,400 --> 00:09:21,683
但是如果用Llama3或者mixtral

329
00:09:21,683 --> 00:09:23,966
还有那个千问他之前的版本来去比

330
00:09:23,966 --> 00:09:25,166
他现在的性能效果

331
00:09:25,166 --> 00:09:26,883
确实也是非常的优秀的

332
00:09:26,883 --> 00:09:28,800
而且在一个math和code里面

333
00:09:28,800 --> 00:09:31,083
做了相关的增强的工作

334
00:09:31,083 --> 00:09:34,200
我们回到了最近特别火的一个Llama3.1

335
00:09:34,200 --> 00:09:35,200
所以和Llama3.1

336
00:09:35,200 --> 00:09:36,166
它对比哦

337
00:09:36,166 --> 00:09:37,366
它做性能的对比

338
00:09:37,366 --> 00:09:39,933
就不仅仅比它之前的前身Llama3

339
00:09:39,933 --> 00:09:40,933
还有Llama2了

340
00:09:40,966 --> 00:09:41,966
它比Gpt4

341
00:09:41,966 --> 00:09:43,850
还有claude 3.5

342
00:09:43,883 --> 00:09:46,600
相关的一些网络模型的测评

343
00:09:46,600 --> 00:09:48,250
那在这整个Human Evaluation

344
00:09:48,250 --> 00:09:49,966
或者他的整个技术文章里面

345
00:09:49,966 --> 00:09:51,883
也公布了非常多的测评效果

346
00:09:51,883 --> 00:09:52,966
可以看到基本上

347
00:09:52,966 --> 00:09:54,083
Llama3.1

348
00:09:54,083 --> 00:09:57,133
现在对比起很多的闭源的大模型

349
00:09:57,133 --> 00:10:00,250
说实话都有一些测评的方案略胜一筹

350
00:10:00,250 --> 00:10:02,366
当然你不能说它所有的方案

351
00:10:02,366 --> 00:10:03,083
或者所有的下游任务

352
00:10:03,083 --> 00:10:04,000
都很好

353
00:10:04,000 --> 00:10:05,200
但是至少它现在已经在

354
00:10:05,200 --> 00:10:06,333
很多下游任务

355
00:10:06,333 --> 00:10:09,250
跟GPT4是能够持平或者相对比的

356
00:10:09,566 --> 00:10:10,933
整体来说能归纳为三点

357
00:10:10,933 --> 00:10:12,733
在通用的一些数据集块

358
00:10:12,733 --> 00:10:13,766
通用的一些语料

359
00:10:13,766 --> 00:10:15,000
或通用的面

360
00:10:15,000 --> 00:10:16,933
整体的基准表现的非常的好

361
00:10:16,933 --> 00:10:18,050
而且在编程能力

362
00:10:18,050 --> 00:10:19,333
特别是humanEval

363
00:10:19,333 --> 00:10:21,250
还有MBPP等基准上

364
00:10:21,250 --> 00:10:22,966
取得了非常高的分数

365
00:10:22,966 --> 00:10:23,400
另外的话

366
00:10:23,400 --> 00:10:24,483
在多语言能力

367
00:10:24,483 --> 00:10:25,766
支持了很多种语言

368
00:10:25,766 --> 00:10:27,250
好像是9个国家语言

369
00:10:27,250 --> 00:10:28,333
还是11个国家的语言

370
00:10:28,333 --> 00:10:29,850
整体效果也是非常

371
00:10:30,166 --> 00:10:31,933
所以也非常欢迎大家去看一下

372
00:10:31,933 --> 00:10:32,600
仔细的看一下

373
00:10:32,600 --> 00:10:34,000
每个下游任务相关的内容

374
00:10:34,000 --> 00:10:34,933
当然ZOMI后面

375
00:10:34,933 --> 00:10:36,483
也希望能够开一期

376
00:10:36,483 --> 00:10:38,366
专门针对下游任务进行解析

377
00:10:38,366 --> 00:10:39,533
每个下游任务到底怎么样的

378
00:10:39,533 --> 00:10:40,966
他的数据长成什么样子的

379
00:10:40,966 --> 00:10:41,933
一些相关的内容

380
00:10:41,933 --> 00:10:43,050
跟大家一起去剖析一下

381
00:10:43,050 --> 00:10:44,050
相关的技术点

382
00:10:45,533 --> 00:10:46,533
好了废话不多说

383
00:10:46,533 --> 00:10:48,166
我们马上来到了第三个内容

384
00:10:48,166 --> 00:10:50,000
大模型的一个降价潮

385
00:10:50,850 --> 00:10:51,600
ZOMI的语文

386
00:10:51,600 --> 00:10:53,333
或者ZOMI的普通话的不太标准

387
00:10:53,333 --> 00:10:54,166
大家原谅一下

388
00:10:54,166 --> 00:10:54,966
就着听吧

389
00:10:54,966 --> 00:10:56,800
整个大模型的API的降价的时间

390
00:10:56,800 --> 00:10:58,166
我们还是回到

391
00:10:58,166 --> 00:10:59,000
5月份

392
00:10:59,000 --> 00:11:00,733
实际上5月份或者4月份的时候

393
00:11:00,733 --> 00:11:01,883
DeepSeek第一个版本的

394
00:11:01,883 --> 00:11:03,566
或者DeepSeek第二个版本

395
00:11:03,566 --> 00:11:05,533
其实打起了整个价格战

396
00:11:05,533 --> 00:11:07,883
因为整个MOE模型MOE的结构

397
00:11:07,883 --> 00:11:09,533
说实话我们会单独的去说

398
00:11:09,533 --> 00:11:11,166
它整体在推理方面的成本

399
00:11:11,166 --> 00:11:13,166
说实话是非常占优势的

400
00:11:13,166 --> 00:11:14,366
因此五月六号的时候

401
00:11:14,366 --> 00:11:16,250
DeepSeek就发布了自己的第二代的

402
00:11:16,250 --> 00:11:17,533
一个MOE的大模型

403
00:11:17,533 --> 00:11:18,366
然后在

404
00:11:18,366 --> 00:11:19,450
五月十一号的时候

405
00:11:19,483 --> 00:11:19,966
智谱

406
00:11:19,966 --> 00:11:23,283
也发布了它的glm 3 turbo的大模型

407
00:11:23,483 --> 00:11:24,166
而同期

408
00:11:24,166 --> 00:11:26,566
国外的OpenAI也公布了它

409
00:11:26,566 --> 00:11:28,000
我会调个价格

410
00:11:28,000 --> 00:11:29,133
当然这个国外的

411
00:11:29,133 --> 00:11:31,483
还是没有跟国内去打价格战的

412
00:11:31,483 --> 00:11:33,000
而整个国内价格战

413
00:11:33,000 --> 00:11:36,533
就是从幻方的5月6号开始

414
00:11:36,533 --> 00:11:38,000
真正的把价格打起来

415
00:11:38,000 --> 00:11:39,733
因此不论是火山引擎

416
00:11:39,733 --> 00:11:42,533
阿里云还有百度智能云还有腾讯云

417
00:11:42,533 --> 00:11:43,800
各种各样的云

418
00:11:43,800 --> 00:11:46,400
都开始在卷大模型的价格战

419
00:11:46,400 --> 00:11:49,400
也是把大模型的价格打下来了

420
00:11:49,400 --> 00:11:51,166
那可以看到从时间轴来看

421
00:11:51,166 --> 00:11:52,800
整体的价格基本上

422
00:11:52,800 --> 00:11:56,933
现在已经去到从分到厘相关的计算了

423
00:11:56,933 --> 00:11:57,883
而计算的单位

424
00:11:57,883 --> 00:11:59,733
也就是每千tokens

425
00:11:59,733 --> 00:12:01,733
作为一个收费的单位

426
00:12:01,733 --> 00:12:03,450
当然了有一些的收费

427
00:12:03,450 --> 00:12:06,133
它是会以会员的方式来进行收费

428
00:12:06,133 --> 00:12:08,133
有些按TOKEN进行收费

429
00:12:08,450 --> 00:12:08,800
有些

430
00:12:08,800 --> 00:12:11,933
可能会按年或者季度来进行收费

431
00:12:13,133 --> 00:12:14,683
那接着我们来到了第四个内容

432
00:12:14,683 --> 00:12:17,566
就是回顾一下国内的相关的大模型

433
00:12:17,566 --> 00:12:20,850
说实话从2023年1月份的时候

434
00:12:20,850 --> 00:12:21,800
zomi就已经决定了

435
00:12:21,800 --> 00:12:22,533
公司里面

436
00:12:22,533 --> 00:12:24,883
我们一定要去坚定的去走Llama的路线

437
00:12:24,883 --> 00:12:25,333
的时候

438
00:12:25,333 --> 00:12:28,283
说实话Llama当时只是被迫开源出来了

439
00:12:28,283 --> 00:12:30,200
而整体业界是没有怎么更新的

440
00:12:30,400 --> 00:12:30,933
自那之后

441
00:12:30,933 --> 00:12:32,966
其实大家其实也有一个共识

442
00:12:32,966 --> 00:12:33,566
就是发现

443
00:12:33,566 --> 00:12:36,050
确实Llama他性能效果也非常好

444
00:12:36,050 --> 00:12:38,283
而且他公布了很多相关的技术细节

445
00:12:38,283 --> 00:12:39,283
因此基于Llama

446
00:12:39,283 --> 00:12:40,100
国内

447
00:12:40,100 --> 00:12:42,100
就有了很多各种各样的Llama的衍生

448
00:12:42,100 --> 00:12:43,500
当然了aplaca

449
00:12:43,500 --> 00:12:44,700
还有Chinese aplaca

450
00:12:44,700 --> 00:12:45,983
还有各种各样llama

451
00:12:45,983 --> 00:12:47,933
其实都是羊驼或者相关的

452
00:12:47,933 --> 00:12:48,900
一些变称了

453
00:12:49,216 --> 00:12:50,450
中国有一个很有意思的就是

454
00:12:50,450 --> 00:12:52,333
华佗都出来了

455
00:12:52,333 --> 00:12:53,216
那有点过分了

456
00:12:53,216 --> 00:12:54,300
虽然都是驼

457
00:12:54,616 --> 00:12:55,700
开个玩笑

458
00:12:55,733 --> 00:12:56,500
所以说

459
00:12:56,500 --> 00:12:58,733
基于Llama做一个衍生的分支

460
00:12:58,733 --> 00:13:00,616
其实现在越来越夸张了

461
00:13:00,616 --> 00:13:01,700
所以我们可以预测

462
00:13:01,700 --> 00:13:02,900
Llama3的出来了

463
00:13:02,900 --> 00:13:05,583
也会国内很多很多的大模型的厂商

464
00:13:05,616 --> 00:13:06,700
或大模型的公司

465
00:13:06,700 --> 00:13:08,383
或者一些微调的应用的公司

466
00:13:08,383 --> 00:13:10,850
也会去Llama来进行一个微调

467
00:13:10,850 --> 00:13:13,133
或者跟进Llama的基数线的了解

468
00:13:13,133 --> 00:13:14,333
而国内的相关的信息之后

469
00:13:14,333 --> 00:13:14,933
我们看一下

470
00:13:14,933 --> 00:13:17,333
AI基础大模型的一个相关的一个情况

471
00:13:17,333 --> 00:13:18,183
首先

472
00:13:18,183 --> 00:13:19,133
AI基础大模型

473
00:13:19,133 --> 00:13:22,900
肯定会分为闭源跟开源相关的两种

474
00:13:23,050 --> 00:13:24,183
而在整个闭源

475
00:13:24,183 --> 00:13:25,533
国外最重要的

476
00:13:25,533 --> 00:13:30,100
就是OpenAI的GPT相关的系列了

477
00:13:30,100 --> 00:13:31,300
还有谷歌的Gemini

478
00:13:31,300 --> 00:13:33,100
和国外的Claude

479
00:13:33,250 --> 00:13:34,533
这个claude、跟OpenAI

480
00:13:34,533 --> 00:13:37,333
也是国外大模型的一个四小龙之一

481
00:13:37,333 --> 00:13:39,650
那国内的其实一些大模型

482
00:13:39,650 --> 00:13:40,933
我们能数的就是

483
00:13:40,933 --> 00:13:41,733
文心一言

484
00:13:41,733 --> 00:13:42,633
百度的

485
00:13:42,633 --> 00:13:44,983
华为有自己的盘古

486
00:13:44,983 --> 00:13:45,933
还有星火呀

487
00:13:45,933 --> 00:13:46,700
豆包哦

488
00:13:46,700 --> 00:13:48,016
这里面漏了个千问的

489
00:13:48,016 --> 00:13:50,416
基本上就是国内闭源的相关的情况

490
00:13:50,783 --> 00:13:51,783
开源的大模型

491
00:13:51,783 --> 00:13:53,133
反而是越来越多

492
00:13:53,133 --> 00:13:54,850
而开源的大模型的性能

493
00:13:54,850 --> 00:13:58,333
也是一直在直逼闭源的大模型的

494
00:13:58,333 --> 00:13:59,216
当然谷歌

495
00:13:59,583 --> 00:14:00,583
小参数量规模

496
00:14:00,583 --> 00:14:02,733
也会做一个开源的

497
00:14:02,733 --> 00:14:05,050
当然Mate也会坚定的走开源的路线

498
00:14:05,050 --> 00:14:06,100
还有mixtral

499
00:14:06,100 --> 00:14:07,616
还有那个stable AI

500
00:14:07,616 --> 00:14:08,183
各种各样的

501
00:14:08,183 --> 00:14:09,333
国外的大公司

502
00:14:09,333 --> 00:14:11,416
也在坚持开源的路线

503
00:14:11,416 --> 00:14:12,183
而国内

504
00:14:12,183 --> 00:14:13,100
就有义通

505
00:14:13,100 --> 00:14:14,183
阿里的千问

506
00:14:14,183 --> 00:14:15,250
还有腾讯的混元

507
00:14:15,250 --> 00:14:16,100
虽然混元

508
00:14:16,100 --> 00:14:16,933
效果一般般

509
00:14:16,933 --> 00:14:18,533
中国电信的星辰

510
00:14:18,533 --> 00:14:19,583
说话用的也比较一般

511
00:14:19,583 --> 00:14:20,016
大家

512
00:14:20,016 --> 00:14:22,416
主要还是根据义通这个大模型

513
00:14:22,416 --> 00:14:25,016
那下面这些说实话都一般般了

514
00:14:25,250 --> 00:14:25,650
所以说

515
00:14:25,650 --> 00:14:27,333
大家想了解一下整个AI技术

516
00:14:27,333 --> 00:14:28,850
Llama现在情况也可以重点

517
00:14:28,850 --> 00:14:29,783
参考一下这个表

518
00:14:29,783 --> 00:14:30,183
当然了

519
00:14:30,183 --> 00:14:32,583
现在的这个表也在不断的在更新

520
00:14:32,616 --> 00:14:33,816
包括激越星辰

521
00:14:33,816 --> 00:14:36,816
Kimi相关的也在不断的去刷榜

522
00:14:36,983 --> 00:14:37,983
突然可能某一天

523
00:14:37,983 --> 00:14:39,850
又迎来了一个新的玩家

524
00:14:39,850 --> 00:14:40,383
那总体

525
00:14:40,383 --> 00:14:41,183
我们盘点了一下

526
00:14:41,183 --> 00:14:42,900
开源大模型的具体的优点

527
00:14:42,900 --> 00:14:43,900
那首先优点

528
00:14:43,900 --> 00:14:45,450
就是透明性和可验证性

529
00:14:45,450 --> 00:14:46,333
相对比较好

530
00:14:46,333 --> 00:14:48,583
你要社区的协作力和创新性也比较好

531
00:14:48,583 --> 00:14:51,333
而且它非常利于教育和相关的学习

532
00:14:51,533 --> 00:14:53,533
另外缺点就是可能现在来看

533
00:14:53,533 --> 00:14:54,933
商业的竞争力是不足的

534
00:14:54,933 --> 00:14:56,650
安全和隐私是没有得到保障

535
00:14:56,650 --> 00:14:57,450
因为我开源

536
00:14:57,450 --> 00:14:58,216
我免费

537
00:14:58,216 --> 00:15:01,016
我还管什么安全和隐私

538
00:15:01,333 --> 00:15:02,500
对吧那我们看一下

539
00:15:02,500 --> 00:15:04,216
闭源大模型的相关的优点

540
00:15:04,216 --> 00:15:06,133
第一个就是它的商业化盈利程度

541
00:15:06,133 --> 00:15:08,183
说实话还相对比较好的

542
00:15:08,183 --> 00:15:10,583
那它还有一些控制保护的相关的license

543
00:15:10,583 --> 00:15:11,650
相关的约束

544
00:15:11,900 --> 00:15:14,650
能够得到公司的云的资源和支持

545
00:15:14,650 --> 00:15:15,300
那云化

546
00:15:15,300 --> 00:15:15,900
其实很重要

547
00:15:15,900 --> 00:15:17,050
因为现在大模型

548
00:15:17,050 --> 00:15:17,933
大部分都会跑

549
00:15:17,933 --> 00:15:19,650
在我们的云服务器里面了

550
00:15:19,650 --> 00:15:21,016
跑在真正的端侧那些

551
00:15:21,016 --> 00:15:23,016
现在来看还是相对比较少

552
00:15:23,016 --> 00:15:23,650
但是未来

553
00:15:23,650 --> 00:15:25,933
我们预计大模型的端侧的落地

554
00:15:25,933 --> 00:15:27,250
肯定会越来越多哦

555
00:15:27,900 --> 00:15:28,533
另外的话

556
00:15:28,533 --> 00:15:30,383
必然大模型也会有一些缺点

557
00:15:30,383 --> 00:15:31,583
就是透明性不足

558
00:15:31,583 --> 00:15:33,216
创新肯定会受到限制

559
00:15:33,216 --> 00:15:35,100
有可能也会从开源的大模型里面的

560
00:15:35,100 --> 00:15:37,583
借鉴很多相关的一些技术点过来

561
00:15:37,583 --> 00:15:38,133
另外的话

562
00:15:38,133 --> 00:15:39,383
成本和准入门槛

563
00:15:39,383 --> 00:15:41,133
还是相对比较高的

564
00:15:41,216 --> 00:15:41,983
那整体

565
00:15:41,983 --> 00:15:44,100
我们去做了一个横向的对比

566
00:15:44,100 --> 00:15:46,250
开源和闭源的大模型

567
00:15:46,650 --> 00:15:48,500
主要是从透明性和可控制性

568
00:15:48,583 --> 00:15:50,383
创新速度和商业应用

569
00:15:50,416 --> 00:15:52,250
还有资源共享和独占情况

570
00:15:52,250 --> 00:15:52,983
安全隐私

571
00:15:52,983 --> 00:15:54,100
做一个横向的对比

572
00:15:54,100 --> 00:15:54,983
大家有兴趣

573
00:15:54,983 --> 00:15:56,700
也可以慢慢看一下这个表

574
00:15:56,700 --> 00:15:59,183
ZOMi就不再的一一的跟大家念了

575
00:15:59,250 --> 00:16:00,416
了解完这个内容之后

576
00:16:00,416 --> 00:16:03,050
我们马上进入到下一个话题

577
00:16:03,050 --> 00:16:05,333
就是整个大模型的发展和思考

578
00:16:05,533 --> 00:16:06,100
每一期视频

579
00:16:06,100 --> 00:16:07,250
我们其实最重要的是

580
00:16:07,250 --> 00:16:08,733
通过一些技术手段的分析

581
00:16:08,733 --> 00:16:09,700
然后ZOMI

582
00:16:09,700 --> 00:16:11,933
去简单的阐述一些业界的观点

583
00:16:11,933 --> 00:16:13,050
还有自己的观点

584
00:16:13,050 --> 00:16:13,700
那这里面

585
00:16:13,700 --> 00:16:15,100
我们也同样的去看一下大模型

586
00:16:15,100 --> 00:16:18,250
开源和闭源相关那些分析的思考点哦

587
00:16:19,500 --> 00:16:21,100
首先说实话

588
00:16:21,450 --> 00:16:22,933
扎心了扎心了

589
00:16:22,933 --> 00:16:24,533
为什么小扎这么扎心

590
00:16:24,533 --> 00:16:26,816
不为什么小扎这么热心

591
00:16:26,816 --> 00:16:29,416
这么去开源世界规模最大

592
00:16:29,416 --> 00:16:33,900
性能最好的开源大模型Llama3.1

593
00:16:34,050 --> 00:16:35,416
那要回答这个问题

594
00:16:35,416 --> 00:16:36,733
说实话我们都不用猜

595
00:16:36,733 --> 00:16:40,533
因为Meta里面的扎克伯格

596
00:16:40,533 --> 00:16:42,216
我也不知道他的英文怎么读了

597
00:16:42,250 --> 00:16:43,850
Llama3.1发布之后

598
00:16:43,850 --> 00:16:45,783
就受到一个AI博主的采访

599
00:16:45,783 --> 00:16:48,050
然后就了解Llama3的一个超大杯

600
00:16:48,050 --> 00:16:50,050
具体它的一些相关的思考

601
00:16:50,050 --> 00:16:51,100
说实话看到这个图

602
00:16:51,100 --> 00:16:51,900
或者看到

603
00:16:51,983 --> 00:16:53,900
大家可以看一下这个直播采访

604
00:16:54,816 --> 00:16:57,100
它的整个是吧

605
00:16:57,100 --> 00:16:57,850
他的形象

606
00:16:57,850 --> 00:17:00,416
跟他的企业的品牌非常的匹配

607
00:17:00,450 --> 00:17:01,650
当然这是吐槽的问题

608
00:17:01,650 --> 00:17:03,416
我们就不吐槽meta了

609
00:17:03,416 --> 00:17:05,050
反正他就公布了相关的知识

610
00:17:05,050 --> 00:17:06,383
ZOMI就在这里面

611
00:17:06,383 --> 00:17:07,183
特别是

612
00:17:07,650 --> 00:17:10,250
特别是这个里面的发布的文章

613
00:17:10,250 --> 00:17:12,533
就是open source AI path forward

614
00:17:12,816 --> 00:17:13,983
通过这篇文章了

615
00:17:13,983 --> 00:17:15,616
ZOMI就总结了几个点

616
00:17:15,616 --> 00:17:16,133
首先

617
00:17:16,133 --> 00:17:17,983
Llama为什么这么大方的去开源

618
00:17:17,983 --> 00:17:18,533
主要是

619
00:17:18,533 --> 00:17:22,250
想成为整个开源的AI行业的大标准

620
00:17:22,250 --> 00:17:23,816
就像Linux操作系统

621
00:17:24,133 --> 00:17:25,850
基于服务器形态一样哦

622
00:17:25,850 --> 00:17:27,016
他希望能够成为

623
00:17:27,016 --> 00:17:28,983
或者引导整个行业的标准

624
00:17:28,983 --> 00:17:30,100
那我们可以看到

625
00:17:30,183 --> 00:17:32,100
现在的大模型

626
00:17:32,100 --> 00:17:33,016
开源的大模型

627
00:17:33,016 --> 00:17:35,983
其实跟小模型的差距在逐渐的缩小的

628
00:17:35,983 --> 00:17:36,583
而Mate

629
00:17:36,583 --> 00:17:38,650
它预计它可能未来几代的大模型

630
00:17:38,650 --> 00:17:39,700
或者未来几代的

631
00:17:39,700 --> 00:17:42,300
Llama肯定会成为业界最先进

632
00:17:42,300 --> 00:17:43,500
最先进的大模型

633
00:17:43,500 --> 00:17:44,533
因此我要开源

634
00:17:44,533 --> 00:17:45,783
我要引导整个标准

635
00:17:45,783 --> 00:17:46,416
另外的话

636
00:17:46,416 --> 00:17:47,333
为了做这个事情

637
00:17:47,333 --> 00:17:50,216
还建立了非常广泛的开源的生态系统

638
00:17:50,216 --> 00:17:52,250
例如他把Pytorch的框架

639
00:17:52,250 --> 00:17:53,450
也开源出去了

640
00:17:53,450 --> 00:17:55,816
说实话整个Meta的AI格局

641
00:17:55,816 --> 00:17:57,250
还是非常的强的

642
00:17:57,250 --> 00:17:58,016
而PyTorch

643
00:17:58,016 --> 00:17:59,650
在华为昇腾

644
00:17:59,650 --> 00:18:02,850
也贡献了很多相关的代码进去

645
00:18:03,250 --> 00:18:03,850
所以现在

646
00:18:03,850 --> 00:18:05,850
昇腾的硬件支持Llama3.1

647
00:18:05,850 --> 00:18:07,250
其实很快的支持起来了

648
00:18:07,250 --> 00:18:10,416
因为他已经原生的支持AI框架PyTorch

649
00:18:10,416 --> 00:18:11,133
那换话题了

650
00:18:11,133 --> 00:18:12,933
或者打了个小广告哦

651
00:18:26,100 --> 00:18:27,983
记得Llama为了实现这个内容

652
00:18:27,983 --> 00:18:29,250
后来成为行业标准

653
00:18:29,250 --> 00:18:31,416
也在跟很多国外的公司

654
00:18:31,416 --> 00:18:32,416
去做推进

655
00:18:32,416 --> 00:18:33,733
希望帮助更多的企业

656
00:18:33,733 --> 00:18:35,850
使用Llama进行一个训练和蒸馏

657
00:18:36,100 --> 00:18:37,650
自定义的一些大模型

658
00:18:37,650 --> 00:18:40,100
这就是为什么meta这么大方的原因了

659
00:18:40,100 --> 00:18:41,450
因为他其实自己都说了

660
00:18:41,450 --> 00:18:42,733
我们都不用猜是吧

661
00:18:42,783 --> 00:18:43,416
那最后

662
00:18:43,416 --> 00:18:46,733
我们看一下整个开源的大模型的动力

663
00:18:46,733 --> 00:18:47,250
说实话

664
00:18:47,250 --> 00:18:49,900
更多的是考虑一个自身品牌影响力

665
00:18:49,900 --> 00:18:52,383
还有市场的份额的需求来去做的

666
00:18:52,383 --> 00:18:54,650
也会吸引更多的开发者来到

667
00:18:54,650 --> 00:18:55,816
我们整个开源大模型

668
00:18:55,816 --> 00:18:57,850
还建立整个行业生态的标准

669
00:18:57,850 --> 00:18:58,333
那这个

670
00:18:58,333 --> 00:19:00,300
就开源的大模型的整体的动力

671
00:19:00,300 --> 00:19:01,983
也是业界达成了共识

672
00:19:01,983 --> 00:19:02,900
那我们现在来看看

673
00:19:02,900 --> 00:19:07,500
开源跟闭源相关的市场份额的争议了

674
00:19:07,816 --> 00:19:08,533
说实话

675
00:19:08,533 --> 00:19:10,050
整个开源的模式

676
00:19:10,050 --> 00:19:11,416
肯定在一定程度上

677
00:19:11,416 --> 00:19:14,300
去蚕食很多闭源的份额

678
00:19:14,333 --> 00:19:16,416
不管是开源还是闭源也好

679
00:19:16,416 --> 00:19:18,533
他肯定会在短期的时间内了

680
00:19:18,533 --> 00:19:19,650
互相的去博弈

681
00:19:20,500 --> 00:19:22,100
也就是周弘毅

682
00:19:22,100 --> 00:19:23,183
红衣大叔

683
00:19:23,183 --> 00:19:24,333
跟我们的李校长

684
00:19:24,333 --> 00:19:27,183
李彦宏校长里面很大的一个争议了

685
00:19:27,500 --> 00:19:27,933
那现在

686
00:19:27,933 --> 00:19:30,016
我们可以看到24年的百模大战

687
00:19:30,016 --> 00:19:32,416
厂商已经不是进入到下半场了

688
00:19:32,416 --> 00:19:34,783
ZOMI认为已经进入到尾声了

689
00:19:34,816 --> 00:19:36,783
目前国内的很多大模型厂商

690
00:19:36,783 --> 00:19:37,333
只有百度

691
00:19:37,333 --> 00:19:37,983
月之暗面

692
00:19:37,983 --> 00:19:40,333
其实还在坚持自己的闭源

693
00:19:40,333 --> 00:19:40,983
而幻方

694
00:19:40,983 --> 00:19:41,383
阿里

695
00:19:41,383 --> 00:19:41,933
商汤

696
00:19:41,933 --> 00:19:43,533
还有很多的玩家

697
00:19:43,533 --> 00:19:46,050
其实已经很多的走向了开源

698
00:19:46,050 --> 00:19:47,050
或者有一部分

699
00:19:47,050 --> 00:19:47,816
已经部分走向

700
00:19:47,816 --> 00:19:50,016
开源和闭源的一个兼顾了

701
00:19:50,016 --> 00:19:50,783
整体来说

702
00:19:50,783 --> 00:19:52,183
开源也是慢慢的倒逼着

703
00:19:52,183 --> 00:19:53,700
闭源相关的大模型

704
00:19:53,700 --> 00:19:55,216
不断的去往前引进

705
00:19:55,216 --> 00:19:55,733
那现在

706
00:19:55,733 --> 00:19:57,933
我们已经来到了最后的一公里

707
00:19:57,933 --> 00:19:58,933
现在来看

708
00:19:58,933 --> 00:20:01,650
嗯ZOMI为了入局L0大模型厂商了

709
00:20:01,650 --> 00:20:03,416
或者已经击溃了

710
00:20:03,416 --> 00:20:05,100
相对比较渺茫

711
00:20:05,250 --> 00:20:07,216
对于很多垂直行业的一些大模型

712
00:20:07,216 --> 00:20:08,133
特别是工业大模型

713
00:20:08,133 --> 00:20:09,900
他的预训练的机遇并不大

714
00:20:09,983 --> 00:20:11,900
转而我们现在可能更多厂商

715
00:20:11,900 --> 00:20:13,583
或更多的应用了

716
00:20:13,583 --> 00:20:14,933
或者更多的创业公司

717
00:20:14,933 --> 00:20:16,133
去做一些开源的大模型

718
00:20:16,133 --> 00:20:18,183
加上智能体或者RAG

719
00:20:18,183 --> 00:20:20,050
解决特定的应用场景和问题

720
00:20:20,050 --> 00:20:21,900
可能更有机会

721
00:20:22,016 --> 00:20:22,900
那未来

722
00:20:22,900 --> 00:20:24,383
我们肯定哦

723
00:20:25,016 --> 00:20:25,533
虽然

724
00:20:25,533 --> 00:20:27,733
我们现在还是围绕着开源和闭源

725
00:20:27,733 --> 00:20:29,650
相关的在不断的争议

726
00:20:29,650 --> 00:20:30,900
但是整个行业

727
00:20:30,900 --> 00:20:32,183
已经有了共识了

728
00:20:32,183 --> 00:20:34,050
就没有最后一公里的应用

729
00:20:34,050 --> 00:20:35,250
和商业化落地

730
00:20:35,383 --> 00:20:36,933
开源和闭源的大模型

731
00:20:36,933 --> 00:20:38,583
肯定也会失去意义的

732
00:20:38,583 --> 00:20:40,783
因此现在把价格战打下来呀

733
00:20:40,783 --> 00:20:42,133
不管是开源和闭源了

734
00:20:42,133 --> 00:20:44,700
都是希望最后一公里的应用

735
00:20:44,700 --> 00:20:46,650
能够快速的涌现

736
00:20:47,383 --> 00:20:50,300
我简单的跟大家分了5个内容

737
00:20:50,300 --> 00:20:51,100
去聊一聊

738
00:20:51,100 --> 00:20:51,450
第一个

739
00:20:51,450 --> 00:20:53,016
就是看看李校长的一个论状

740
00:20:53,016 --> 00:20:54,583
看一下大模型的性能

741
00:20:54,583 --> 00:20:55,650
接着看一下性能中

742
00:20:55,650 --> 00:20:57,850
我们看一下降价潮引起的

743
00:20:57,850 --> 00:21:00,416
国内的大模型的一个具体的发展

744
00:21:00,500 --> 00:21:01,933
最后对大模型的技术

745
00:21:01,933 --> 00:21:04,450
进行一个思考和总结

746
00:21:04,450 --> 00:21:05,100
今天内容

747
00:21:05,100 --> 00:21:06,050
就到这谢谢各位

748
00:21:06,050 --> 00:21:06,850
拜了个拜

