1
00:00:00,000 --> 00:00:01,550
内容/录制：ZOMI酱，视频剪辑/字幕：梁嘉铭


2
00:00:05,250 --> 00:00:05,483
哈喽

3
00:00:05,483 --> 00:00:05,883
大家好

4
00:00:05,883 --> 00:00:07,933
我是那个好男儿志在四方

5
00:00:07,933 --> 00:00:08,683
喝西北风

6
00:00:08,683 --> 00:00:10,283
从不声张的zomi

7
00:00:12,283 --> 00:00:13,883
今天呢我们来到了看一下

8
00:00:13,883 --> 00:00:16,283
端到端的自动驾驶具体的算法

9
00:00:16,283 --> 00:00:16,966
来解读

10
00:00:16,966 --> 00:00:20,083
去了解什么是端到端的自动驾驶

11
00:00:20,533 --> 00:00:21,600
今天这期视频呢

12
00:00:21,600 --> 00:00:23,650
主要是跟大家一起去分享一下

13
00:00:23,650 --> 00:00:25,200
相关比较硬核的东西了

14
00:00:25,200 --> 00:00:27,966
可能会相对比较枯燥无聊

15
00:00:27,966 --> 00:00:29,400
虽然我已经很努力的

16
00:00:29,400 --> 00:00:31,366
讲的相对比较轻松了

17
00:00:31,766 --> 00:00:32,883
虽然没什么效果

18
00:00:33,283 --> 00:00:34,933
但是我们回到这期视频我们看一下

19
00:00:34,933 --> 00:00:35,766
今天主要是看一下

20
00:00:35,766 --> 00:00:37,883
端到端的自动驾驶技术的路线

21
00:00:37,883 --> 00:00:39,450
到底是怎么样的

22
00:00:39,450 --> 00:00:42,083
主要是关心端到端自动驾驶的路线呢

23
00:00:42,083 --> 00:00:43,766
到底是选用百度的这种

24
00:00:43,766 --> 00:00:45,283
还是特斯拉这种方式

25
00:00:45,733 --> 00:00:47,566
那在整个自动驾驶里面呢

26
00:00:47,566 --> 00:00:50,133
其实我们分开很多相关的内容啊

27
00:00:50,133 --> 00:00:51,600
第一个呢就是Papeline

28
00:00:51,600 --> 00:00:52,450
整个自动驾驶

29
00:00:52,450 --> 00:00:56,166
我们会感知预测规划三个内容

30
00:00:56,166 --> 00:00:57,650
当然了每个内容里面

31
00:00:57,650 --> 00:01:00,333
可能又有很多很多小模型的出现的

32
00:01:00,333 --> 00:01:00,733
因此

33
00:01:00,733 --> 00:01:03,333
我们会出现一个整个级联的方式

34
00:01:03,333 --> 00:01:04,333
那整个级联的方式

35
00:01:04,333 --> 00:01:05,883
我们可以把它串联起来

36
00:01:05,883 --> 00:01:08,050
就变成了一个所谓的pipleline

37
00:01:08,333 --> 00:01:10,933
在整个大模型的测试的环节

38
00:01:10,933 --> 00:01:12,883
我们就会有个相对应的Benchmarking

39
00:01:12,883 --> 00:01:13,966
这Benchmarking里面

40
00:01:13,966 --> 00:01:17,000
就分开真实世界和开环跟闭环

41
00:01:17,000 --> 00:01:18,250
我们也会讲讲

42
00:01:18,250 --> 00:01:20,083
这一个相关的测评的方式

43
00:01:20,083 --> 00:01:22,083
最后我们很重要的

44
00:01:22,083 --> 00:01:23,400
或者在这个视频里面很重要的

45
00:01:23,400 --> 00:01:25,683
就是整个自动驾驶的眼睛的路径了

46
00:01:25,683 --> 00:01:28,250
说实话自动驾驶我们一般呢叫做IL

47
00:01:28,683 --> 00:01:30,766
也就是imitation learning

48
00:01:30,766 --> 00:01:32,250
学习模拟学习都好了

49
00:01:32,250 --> 00:01:33,850
基本上呢都会以IL的方式

50
00:01:33,850 --> 00:01:35,483
不是以DL或者其他的方式

51
00:01:35,766 --> 00:01:36,850
或者IO的方式

52
00:01:36,850 --> 00:01:38,450
说出来是用的相对比较少的

53
00:01:38,450 --> 00:01:40,333
大部分呢都是IL

54
00:01:40,333 --> 00:01:41,083
那我们可以看到

55
00:01:41,083 --> 00:01:42,966
其实整个真正的自动驾驶

56
00:01:42,966 --> 00:01:45,450
用了深度学习呢是从2016年开始

57
00:01:45,683 --> 00:01:46,483
当时开始之后

58
00:01:46,483 --> 00:01:47,166
大家开始的

59
00:01:47,166 --> 00:01:49,283
大量的去用了一个BE的net

60
00:01:49,283 --> 00:01:50,566
也是BE网络模型

61
00:01:50,566 --> 00:01:51,133
那接着

62
00:01:51,133 --> 00:01:53,883
可能到了2022年到2021年的时候

63
00:01:53,883 --> 00:01:56,366
会慢慢的引入了一些transformer的结构

64
00:01:56,366 --> 00:01:57,683
也就是attention的结构

65
00:01:58,133 --> 00:01:58,566
然后

66
00:01:58,566 --> 00:02:00,400
就慢慢的把大模型相关的技术

67
00:02:00,400 --> 00:02:01,200
用起来

68
00:02:01,200 --> 00:02:03,966
但是呢到了2022年到2023年的时候

69
00:02:03,966 --> 00:02:04,683
其实大部分

70
00:02:04,683 --> 00:02:07,450
还是用了很多各种各样的学习的方式

71
00:02:07,450 --> 00:02:08,450
或者机器学习方式

72
00:02:08,450 --> 00:02:10,333
还有各种各样的规划控制的算法

73
00:02:10,733 --> 00:02:12,250
到了这个很重要的时间点

74
00:02:12,250 --> 00:02:13,400
就2023年的时候

75
00:02:13,400 --> 00:02:14,283
特斯拉就宣布了

76
00:02:14,283 --> 00:02:16,000
他自己用了一个端到端的大模型

77
00:02:16,250 --> 00:02:18,600
因此就引起了整个

78
00:02:18,600 --> 00:02:19,450
智能驾驶圈的

79
00:02:19,450 --> 00:02:21,966
一个具体的技术的新的革命和演进了

80
00:02:21,966 --> 00:02:25,533
也就是说今天V2的内容E2E端到端

81
00:02:25,533 --> 00:02:26,533
那今天这个视频

82
00:02:26,533 --> 00:02:29,133
主要是跟大家去简单的回顾一下

83
00:02:29,133 --> 00:02:30,366
2016年的时候

84
00:02:30,366 --> 00:02:33,133
非常非常火的BVNET到底是个什么东西

85
00:02:33,683 --> 00:02:35,533
接着我们看一下2020的时候

86
00:02:35,533 --> 00:02:37,766
特斯拉提出了一个occupants net 

87
00:02:38,083 --> 00:02:40,450
那这个网络模型到底有什么区别

88
00:02:40,450 --> 00:02:41,566
到了2023年的时候

89
00:02:41,566 --> 00:02:44,366
特斯拉又提出了一个E2E网络模型

90
00:02:44,366 --> 00:02:45,566
端到端的自动驾驶

91
00:02:45,566 --> 00:02:45,883
因此

92
00:02:45,883 --> 00:02:48,733
又引起了业界很多相关的新的研究

93
00:02:48,733 --> 00:02:49,800
可以看到了自动

94
00:02:49,800 --> 00:02:50,400
驾驶这个领域啊

95
00:02:50,400 --> 00:02:51,333
一直都是特斯拉

96
00:02:51,333 --> 00:02:53,400
在做一个前沿的牵引

97
00:02:53,400 --> 00:02:54,650
除了这段时间

98
00:02:54,650 --> 00:02:56,650
可能在学术界的进行探索

99
00:02:56,650 --> 00:02:58,333
那到了后面的一段时间

100
00:02:58,333 --> 00:02:59,366
其实特斯拉

101
00:02:59,566 --> 00:03:02,133
整体还是牵引整个业界的技术的

102
00:03:02,133 --> 00:03:03,483
往前的推进的

103
00:03:03,483 --> 00:03:04,133
那我们今天

104
00:03:04,133 --> 00:03:05,283
是不是来到了

105
00:03:05,283 --> 00:03:07,800
马上开始我们相关技术的内容

106
00:03:09,083 --> 00:03:09,850
后面的内容

107
00:03:09,850 --> 00:03:11,733
说实话毕竟是讲技术

108
00:03:11,733 --> 00:03:13,200
所以相对来说

109
00:03:13,200 --> 00:03:14,683
都会有点枯燥又无聊

110
00:03:14,733 --> 00:03:15,400
那第一个内容

111
00:03:15,400 --> 00:03:17,933
我们就看一下传统的级联算法

112
00:03:17,933 --> 00:03:20,050
跟端到端的自动驾驶的算法

113
00:03:20,050 --> 00:03:21,733
到底有什么区别

114
00:03:22,000 --> 00:03:22,566
那可以看到

115
00:03:22,566 --> 00:03:24,000
在整个自动驾驶系统里面

116
00:03:24,000 --> 00:03:25,366
我们的输入的源头

117
00:03:25,366 --> 00:03:28,050
有非常多的不同的传感器

118
00:03:28,166 --> 00:03:29,283
雷达

119
00:03:29,283 --> 00:03:29,800
摄像头

120
00:03:29,800 --> 00:03:30,800
还有激光雷达

121
00:03:30,800 --> 00:03:31,366
毫米波雷达

122
00:03:31,366 --> 00:03:32,283
还有我们的高清地图

123
00:03:32,283 --> 00:03:33,366
还有IMU啊

124
00:03:33,366 --> 00:03:34,533
冠导或者GPS

125
00:03:34,533 --> 00:03:36,283
各种各样的传感器

126
00:03:36,483 --> 00:03:36,850
输进去

127
00:03:36,850 --> 00:03:39,200
我们整个自动驾驶的中控平台

128
00:03:39,200 --> 00:03:40,850
或自动驾驶的系统里面

129
00:03:40,850 --> 00:03:41,450
那这里面

130
00:03:41,450 --> 00:03:43,400
就有1234567

131
00:03:43,400 --> 00:03:45,400
非常多的步骤换完回来

132
00:03:45,400 --> 00:03:46,933
最后给到我们的汽车

133
00:03:46,933 --> 00:03:48,566
进行一个决策控制的

134
00:03:48,566 --> 00:03:49,000
这里面

135
00:03:49,000 --> 00:03:49,800
其实有很多啊

136
00:03:49,800 --> 00:03:51,200
主要是我们的感知定位

137
00:03:51,200 --> 00:03:51,683
目标跟踪

138
00:03:51,683 --> 00:03:52,200
行为跟踪

139
00:03:52,200 --> 00:03:53,400
还有我们的路径规划

140
00:03:53,400 --> 00:03:54,483
决策控制

141
00:03:54,483 --> 00:03:56,283
主要就是这几大模块

142
00:03:56,600 --> 00:03:59,083
去实现我们的一个级联的系统的

143
00:03:59,083 --> 00:04:01,450
那在整个传统的自动驾驶里面

144
00:04:01,450 --> 00:04:04,200
我们会有刚才说到很多个级联的系统

145
00:04:04,200 --> 00:04:05,250
或者每一个小系统

146
00:04:05,250 --> 00:04:06,933
做一个整体的集合的

147
00:04:06,966 --> 00:04:09,083
每一个系统的输入

148
00:04:09,166 --> 00:04:11,083
其实上一个系统的输出

149
00:04:11,083 --> 00:04:12,800
在传统的级联系统里面呢

150
00:04:12,800 --> 00:04:15,333
很讲究的就是上一个系统

151
00:04:15,333 --> 00:04:16,166
或者上一个模块

152
00:04:16,166 --> 00:04:17,283
它的精度

153
00:04:17,283 --> 00:04:18,883
会影响到下一个精度的模块

154
00:04:19,483 --> 00:04:19,766
所以

155
00:04:19,766 --> 00:04:21,766
在级联系统有两个最大的问题

156
00:04:21,766 --> 00:04:23,483
一个就是累计误差

157
00:04:23,483 --> 00:04:25,083
会把我们的误差进行累积

158
00:04:25,083 --> 00:04:25,683
最终影响到

159
00:04:25,683 --> 00:04:27,333
整个最后的系统的一个性能

160
00:04:27,333 --> 00:04:28,800
也就影响到我们自动驾驶

161
00:04:28,850 --> 00:04:31,333
最后的一个具体的效果了

162
00:04:31,333 --> 00:04:33,733
第二个就是会有一个延时

163
00:04:33,733 --> 00:04:35,600
所以它最主要的两个问题

164
00:04:35,600 --> 00:04:36,800
那么现在来看一下

165
00:04:36,800 --> 00:04:38,483
端到端的一个具体的方式

166
00:04:38,483 --> 00:04:40,333
所谓的端到端的其实有两种

167
00:04:40,600 --> 00:04:42,683
第一种是真正的一的端到端

168
00:04:42,683 --> 00:04:43,200
第二种

169
00:04:43,200 --> 00:04:46,083
就把感知决策控制相关的端到端

170
00:04:46,283 --> 00:04:47,733
真正的planning规划呢

171
00:04:47,733 --> 00:04:49,733
和真正的最后做决策

172
00:04:49,766 --> 00:04:50,933
驾驶辅助的时候

173
00:04:50,933 --> 00:04:52,200
它并不是端到端

174
00:04:52,200 --> 00:04:54,083
所以端到端有两种方式

175
00:04:54,083 --> 00:04:56,050
大家可以简单的去区分出来

176
00:04:56,050 --> 00:04:56,883
那我们今天

177
00:04:56,883 --> 00:04:58,166
其实在上一节视频里面呢

178
00:04:58,166 --> 00:05:00,533
跟大家已经去比较过了

179
00:05:00,566 --> 00:05:01,366
级联系统

180
00:05:01,366 --> 00:05:03,400
跟端到端系统的一个具体的区别

181
00:05:03,400 --> 00:05:06,200
可以看到在整个端到端系统里面呢

182
00:05:06,683 --> 00:05:08,400
响应时延还是比较高的

183
00:05:08,400 --> 00:05:10,166
算法的难度呢当然也比较高

184
00:05:10,166 --> 00:05:11,933
累积误差呢也是比较少

185
00:05:11,933 --> 00:05:12,883
在上一个视频里面

186
00:05:12,883 --> 00:05:14,883
其实跟大家已经简单的分享过了

187
00:05:16,133 --> 00:05:17,650
今天的重点来了

188
00:05:17,683 --> 00:05:20,133
现在才是今天这个视频

189
00:05:20,133 --> 00:05:23,133
跟大家去分享的端到端的算法

190
00:05:23,133 --> 00:05:24,533
看一下现在业界最新

191
00:05:24,533 --> 00:05:27,000
最潮流的端到端的算法

192
00:05:27,000 --> 00:05:28,083
到底是怎么去实现的

193
00:05:28,083 --> 00:05:30,133
特别特斯拉说他的端到端算法

194
00:05:30,166 --> 00:05:30,883
那首先

195
00:05:30,883 --> 00:05:31,683
我们这里面

196
00:05:31,683 --> 00:05:32,683
会分开好几个内容

197
00:05:32,683 --> 00:05:34,566
跟大家去一个分享的

198
00:05:34,566 --> 00:05:36,733
第一个呢就是测评的方案的

199
00:05:36,733 --> 00:05:41,533
测评的方法大模型端到端自动驾驶

200
00:05:41,533 --> 00:05:43,000
那自动驾驶怎么去测评

201
00:05:43,000 --> 00:05:43,966
怎么判断它好和不好

202
00:05:43,966 --> 00:05:45,050
那因此

203
00:05:45,050 --> 00:05:46,650
自动驾驶在学术界

204
00:05:46,650 --> 00:05:47,850
他研究的方式

205
00:05:47,850 --> 00:05:49,483
就衍生了两类

206
00:05:49,483 --> 00:05:51,283
一种叫做闭环的方式

207
00:05:51,283 --> 00:05:53,366
一种叫做开环的方式

208
00:05:53,533 --> 00:05:54,133
所谓的闭环

209
00:05:54,133 --> 00:05:56,766
就是我们在一个模拟器里面去研究

210
00:05:56,766 --> 00:05:58,766
验证那规划了下一步指令

211
00:05:58,766 --> 00:06:00,450
可以被真实的去执行的

212
00:06:00,450 --> 00:06:01,533
那开环的方式

213
00:06:01,533 --> 00:06:02,850
就在已经采集的数据上

214
00:06:02,850 --> 00:06:04,883
进行一个端到端的研究

215
00:06:04,933 --> 00:06:07,333
讲起来很复杂

216
00:06:07,483 --> 00:06:09,283
但是我们简单看看

217
00:06:09,283 --> 00:06:13,283
开环跟闭环具体的一个口语化的内容

218
00:06:13,366 --> 00:06:14,283
所谓的闭环

219
00:06:14,283 --> 00:06:15,883
就是算法驱车

220
00:06:16,050 --> 00:06:16,800
那开环呢

221
00:06:16,800 --> 00:06:18,483
就是算法不控制车

222
00:06:19,200 --> 00:06:20,250
算法控制车

223
00:06:20,250 --> 00:06:22,366
也就在我们的一个

224
00:06:22,483 --> 00:06:24,650
所谓的一个模拟的环境里面呢

225
00:06:24,650 --> 00:06:26,933
我们写了一个规划控制的算法

226
00:06:26,933 --> 00:06:27,966
或自动驾驶的算法

227
00:06:27,966 --> 00:06:29,400
我可以在真正的环境里面

228
00:06:29,400 --> 00:06:30,650
去控制我们这台车

229
00:06:30,683 --> 00:06:32,366
那这种就叫做闭环

230
00:06:32,400 --> 00:06:33,450
那所谓的开环

231
00:06:33,450 --> 00:06:36,483
就是我现在已经录了很多的车道视频

232
00:06:36,533 --> 00:06:38,733
然后我们去控制这台车去执行

233
00:06:38,733 --> 00:06:39,083
但是

234
00:06:39,083 --> 00:06:41,166
这些视频我们也是提前录好了

235
00:06:41,166 --> 00:06:43,483
所以我们没有办法真正去控制这台车

236
00:06:43,483 --> 00:06:45,083
因此我们去预测

237
00:06:45,133 --> 00:06:47,400
跟真实的开车的环境的时候

238
00:06:47,400 --> 00:06:48,400
的那个误差

239
00:06:48,766 --> 00:06:50,200
所以呢数学的本质

240
00:06:50,200 --> 00:06:51,333
就是预测误差

241
00:06:51,333 --> 00:06:53,883
我们叫做predict Error这种方式

242
00:06:53,883 --> 00:06:54,883
因此呢可以看到

243
00:06:54,883 --> 00:06:57,400
现在的根于开环的方式

244
00:06:57,400 --> 00:06:59,883
其实在很多学术界论文里面

245
00:06:59,883 --> 00:07:00,766
用的是最多的

246
00:07:00,766 --> 00:07:01,966
因为大量的数据呢

247
00:07:01,966 --> 00:07:02,366
说实话

248
00:07:02,366 --> 00:07:06,166
是基于一些已经提前录制好的视频

249
00:07:06,400 --> 00:07:07,733
行车驾驶的视频

250
00:07:07,733 --> 00:07:09,400
因此呢常用的开关的指标呢

251
00:07:09,400 --> 00:07:10,850
有L2的距离了

252
00:07:10,933 --> 00:07:14,200
还有collection rate两个相关的指标

253
00:07:14,400 --> 00:07:16,333
那了解完相关的指标之后

254
00:07:16,333 --> 00:07:18,733
我们真正的来看一下相关的一些

255
00:07:18,800 --> 00:07:21,366
真正的网络模型

256
00:07:21,366 --> 00:07:23,650
和端到端自动驾驶系统

257
00:07:23,650 --> 00:07:24,683
我们在应该了解

258
00:07:24,683 --> 00:07:26,800
它之前的一些相关的技术点

259
00:07:27,450 --> 00:07:29,533
哎再真正看BEVNET

260
00:07:29,533 --> 00:07:30,683
所谓的BEV呢

261
00:07:30,683 --> 00:07:32,766
就是birds-eye- view的

262
00:07:32,766 --> 00:07:35,733
鸟瞰图的一种类型的网络模型了

263
00:07:35,800 --> 00:07:37,766
它不是指一个具体的网络模型

264
00:07:37,766 --> 00:07:39,200
而是指一类网络模型

265
00:07:39,733 --> 00:07:42,366
哎虽然现在已经到了凌晨30分的

266
00:07:42,366 --> 00:07:44,650
也就是快12点半了

267
00:07:44,766 --> 00:07:45,650
那不过没关系

268
00:07:45,650 --> 00:07:47,566
大家记得一键三连

269
00:07:47,650 --> 00:07:48,200
那现在

270
00:07:48,200 --> 00:07:50,483
我们回到整个BEVNET了

271
00:07:50,483 --> 00:07:51,483
看图所谓了鸟瞰图

272
00:07:51,483 --> 00:07:54,000
就是我们的一个车载的摄像头

273
00:07:54,000 --> 00:07:56,650
看到的是上面的这些

274
00:07:56,766 --> 00:07:59,333
具体的一些可能摄像头的视频

275
00:07:59,333 --> 00:08:01,050
但所谓的BEV鸟瞰图

276
00:08:01,050 --> 00:08:02,366
我们真正在处理的时候

277
00:08:02,366 --> 00:08:05,483
会把它转换成为类似于下面的这种图

278
00:08:05,533 --> 00:08:07,050
所以大家看到它是一个鸟瞰图

279
00:08:07,050 --> 00:08:08,250
从上面看过来的

280
00:08:08,250 --> 00:08:10,683
就把几个图片呢或者几个视频

281
00:08:10,933 --> 00:08:13,250
融合成一个具体的形态了

282
00:08:13,250 --> 00:08:15,333
那在整个BEVNET里面呢其实现在

283
00:08:15,333 --> 00:08:18,000
已经有非常多的网络模型

284
00:08:18,000 --> 00:08:19,250
所以我们叫做BEVNET

285
00:08:19,250 --> 00:08:20,766
是一系列的网络模型

286
00:08:20,766 --> 00:08:20,933
包括

287
00:08:20,933 --> 00:08:23,883
我们车载摄像头看到的一系列的视频

288
00:08:23,883 --> 00:08:24,800
图片

289
00:08:25,133 --> 00:08:26,966
通过一系列的网络模型

290
00:08:26,966 --> 00:08:28,850
各种各样的网络模型

291
00:08:28,966 --> 00:08:30,566
最后呢变成一个BEVNET

292
00:08:30,566 --> 00:08:31,766
然后输出一个具体的

293
00:08:31,766 --> 00:08:33,483
融合后的一个具体的效果了

294
00:08:33,600 --> 00:08:34,083
那这种

295
00:08:34,083 --> 00:08:37,800
就是整个BEVNET所做的一些相关的工作

296
00:08:38,200 --> 00:08:39,800
至少啊现在包括萝卜快跑

297
00:08:39,800 --> 00:08:42,683
还有华为的很多自动驾驶相关的

298
00:08:42,683 --> 00:08:45,366
都是基于BEV net去实现的

299
00:08:45,366 --> 00:08:45,966
所以大家

300
00:08:45,966 --> 00:08:48,366
一定要去了解一下相关的这个基础点

301
00:08:48,366 --> 00:08:48,850
你了解完

302
00:08:48,850 --> 00:08:49,650
这个之后

303
00:08:50,050 --> 00:08:52,800
我们接下来就来到下一个内容了

304
00:08:52,883 --> 00:08:55,133
叫做栅格网络或者一个空间网络

305
00:08:55,133 --> 00:08:57,283
网格网络了occupants network

306
00:08:57,333 --> 00:08:58,533
那这个网络模型呢

307
00:08:58,533 --> 00:08:59,966
是特斯拉去提出来的

308
00:08:59,966 --> 00:09:01,133
我们现在来了解一下

309
00:09:01,133 --> 00:09:04,683
2.3下一个网络模型的相关的技术点

310
00:09:05,283 --> 00:09:08,733
好我们现在来开始2.3的occupancy Network

311
00:09:08,733 --> 00:09:10,800
那可能英文发音的不太标准呢

312
00:09:10,800 --> 00:09:13,133
大家看一下所谓的网格网络

313
00:09:13,133 --> 00:09:14,083
或者三格网络了

314
00:09:14,083 --> 00:09:17,283
其实呢我输进去的是一系列的

315
00:09:17,283 --> 00:09:18,133
上面能看到的

316
00:09:18,133 --> 00:09:21,166
我们车载全车的一些相关的摄像头

317
00:09:21,600 --> 00:09:22,200
传感器

318
00:09:22,200 --> 00:09:23,283
最后

319
00:09:23,283 --> 00:09:26,083
输出的一个这么一个类型的网络模型

320
00:09:26,083 --> 00:09:26,600
来呢这个呢

321
00:09:26,600 --> 00:09:29,083
就是occupancy Network所做的一系列的工作了

322
00:09:29,083 --> 00:09:30,366
当然我们可以换一个场景

323
00:09:30,366 --> 00:09:32,650
基本上都是这种类型的

324
00:09:32,683 --> 00:09:33,400
那现在

325
00:09:33,400 --> 00:09:34,166
我们可以看到

326
00:09:34,166 --> 00:09:35,450
在整个不同的场景里

327
00:09:35,450 --> 00:09:36,166
整个网络模型

328
00:09:36,166 --> 00:09:38,450
是把车身周围的一些相关的信息

329
00:09:38,450 --> 00:09:41,283
都全部变成一个栅格化的内容

330
00:09:41,533 --> 00:09:42,000
那现在

331
00:09:42,000 --> 00:09:42,683
我们看一下

332
00:09:42,683 --> 00:09:44,133
在这次呢2022年

333
00:09:44,133 --> 00:09:46,800
在aidays里面去发表了相关的记述了

334
00:09:46,800 --> 00:09:49,766
那网络模型的输了就是一系列图片了

335
00:09:50,133 --> 00:09:52,133
特斯拉在AIDsyS里面呢就说了

336
00:09:52,133 --> 00:09:55,850
我是一个纯视觉的模型

337
00:09:55,850 --> 00:09:58,333
和纯视觉的自动驾驶的方案

338
00:09:58,650 --> 00:09:59,166
那因此

339
00:09:59,166 --> 00:10:00,800
在整个特斯拉的方案里面

340
00:10:00,800 --> 00:10:02,566
全都是图片的输入

341
00:10:02,566 --> 00:10:03,533
那图片输入之后呢

342
00:10:03,533 --> 00:10:04,800
就会经过RegNET

343
00:10:04,800 --> 00:10:07,333
然后再经过一个bifpnet

344
00:10:07,333 --> 00:10:07,766
然后

345
00:10:07,766 --> 00:10:11,333
就用了Transformer这个网络模型的结构

346
00:10:11,333 --> 00:10:12,050
那注意了

347
00:10:12,050 --> 00:10:12,566
这里面

348
00:10:12,566 --> 00:10:15,566
用的是attention Transformer的网络模型结构

349
00:10:15,566 --> 00:10:17,250
但是不代表这个网络模型

350
00:10:17,250 --> 00:10:18,683
它是一个大模型

351
00:10:18,683 --> 00:10:20,483
因为它的参数量还没有那么大

352
00:10:20,483 --> 00:10:21,133
那输出

353
00:10:21,133 --> 00:10:23,400
有几个第一个呢就是temporal in了

354
00:10:23,400 --> 00:10:25,483
也就是把我们的时序呢进行一个对齐

355
00:10:25,483 --> 00:10:26,766
然后时序对齐完之后

356
00:10:26,766 --> 00:10:28,650
就会把它变成一个具体的feature

357
00:10:28,650 --> 00:10:29,566
就是特性了

358
00:10:29,733 --> 00:10:30,450
给到我们的

359
00:10:30,450 --> 00:10:32,966
一个同样的网络模型的融合层

360
00:10:33,050 --> 00:10:33,600
那接着

361
00:10:33,600 --> 00:10:34,533
进行一个输出

362
00:10:34,533 --> 00:10:36,366
输出的时候进行一个反卷积

363
00:10:36,366 --> 00:10:38,283
最后输出我们的体数

364
00:10:38,333 --> 00:10:40,366
那体数融合完之后

365
00:10:40,450 --> 00:10:43,483
真正的输出就是我们的occupancy

366
00:10:43,483 --> 00:10:44,600
我们的特征

367
00:10:44,600 --> 00:10:46,650
还有我们的刚才的occupancy的一个

368
00:10:48,400 --> 00:10:49,850
occupancy的一个具体的特征

369
00:10:49,850 --> 00:10:51,050
栅格化的特征

370
00:10:51,050 --> 00:10:54,533
还有栅格化最后的一个具体的形状图

371
00:10:54,533 --> 00:10:55,883
或者三维地图了

372
00:10:55,883 --> 00:10:56,650
那这个图

373
00:10:56,650 --> 00:10:58,533
其实更多的像现在呢

374
00:10:58,533 --> 00:11:00,000
其实特斯拉跟华为了

375
00:11:00,000 --> 00:11:01,483
更多的是采用这种方案

376
00:11:01,483 --> 00:11:02,366
这种方有种好处的

377
00:11:02,366 --> 00:11:05,250
就是不依赖于高精地图

378
00:11:06,133 --> 00:11:07,283
这点呢非常的重要

379
00:11:07,283 --> 00:11:11,083
跟百度的萝卜快跑啊是很大的区别

380
00:11:11,083 --> 00:11:12,283
我有一个occupancy

381
00:11:12,283 --> 00:11:14,733
那么可以感知周围的相关的信息

382
00:11:14,733 --> 00:11:15,966
灵敏性强

383
00:11:15,966 --> 00:11:17,083
哪里是地

384
00:11:17,083 --> 00:11:18,200
哪里可以走

385
00:11:18,366 --> 00:11:19,050
那因此

386
00:11:19,050 --> 00:11:19,850
可以看到

387
00:11:20,566 --> 00:11:22,450
在2023年的发布会里面

388
00:11:22,450 --> 00:11:24,133
就说华为的自驾

389
00:11:24,133 --> 00:11:26,733
其实是不依赖于高精地图的

390
00:11:26,733 --> 00:11:28,083
原因就在这里面

391
00:11:28,083 --> 00:11:30,400
确实很多特斯拉引进的相关的技术啊

392
00:11:30,400 --> 00:11:33,250
国内的也就快速的做跟近的

393
00:11:33,283 --> 00:11:34,133
那另外的话

394
00:11:34,133 --> 00:11:35,200
除了特斯拉

395
00:11:35,200 --> 00:11:37,333
刚才讲到了一个相关的技术

396
00:11:37,450 --> 00:11:38,333
就occupancy number

397
00:11:38,333 --> 00:11:41,000
其实特斯拉在2020年的aidays里面

398
00:11:41,000 --> 00:11:42,650
又提出了基于Vector space的

399
00:11:42,650 --> 00:11:43,733
一个基于空间向量的

400
00:11:43,733 --> 00:11:46,483
一个FSD的路径规划

401
00:11:46,566 --> 00:11:47,800
那所谓的路径规划呢

402
00:11:47,800 --> 00:11:49,650
就是planning的工作了

403
00:11:49,650 --> 00:11:51,683
P l a n n i n g哦

404
00:11:51,766 --> 00:11:53,000
现在所谓的planning

405
00:11:53,000 --> 00:11:54,166
说实话

406
00:11:54,533 --> 00:11:56,050
百度在吹牛逼

407
00:11:56,050 --> 00:11:58,800
说他现在是一个panning的规划了

408
00:11:58,800 --> 00:12:00,083
大模型说实话

409
00:12:00,083 --> 00:12:01,250
panning这一块

410
00:12:01,250 --> 00:12:02,450
在机器人研究领域

411
00:12:02,450 --> 00:12:03,766
或者自动驾驶领域了

412
00:12:03,766 --> 00:12:06,400
其实在2022年到2023年的时候

413
00:12:06,400 --> 00:12:08,250
大量的还没有用到神经网络

414
00:12:08,250 --> 00:12:09,166
更多的像特斯拉

415
00:12:09,166 --> 00:12:11,850
他用的还是决策术相关的技术

416
00:12:12,166 --> 00:12:14,083
而国内肯定没有国外走的这么快

417
00:12:14,083 --> 00:12:14,450
所以

418
00:12:14,450 --> 00:12:16,966
像吹自己是一个planning的大模型

419
00:12:17,083 --> 00:12:17,600
基本上

420
00:12:17,600 --> 00:12:18,166
大概率

421
00:12:18,166 --> 00:12:19,166
都是假的

422
00:12:19,333 --> 00:12:20,200
百度用的技术

423
00:12:20,200 --> 00:12:22,166
还是相对比较保守的

424
00:12:22,166 --> 00:12:23,083
而华为用的技术

425
00:12:23,083 --> 00:12:25,200
也会相对激进一点的

426
00:12:25,200 --> 00:12:26,650
特斯拉是最激进的

427
00:12:26,650 --> 00:12:28,800
所以大家可以理解一下相关的内容

428
00:12:29,800 --> 00:12:30,650
哈不知不觉

429
00:12:30,650 --> 00:12:32,250
我们又来到了2.4啊

430
00:12:32,250 --> 00:12:33,483
端到端最新的算法

431
00:12:33,483 --> 00:12:34,366
刚才讲了那么多

432
00:12:34,366 --> 00:12:35,683
其实都是铺垫的

433
00:12:35,733 --> 00:12:37,133
之前的所有的算法

434
00:12:37,133 --> 00:12:37,766
扩了很多

435
00:12:37,766 --> 00:12:39,683
到2022年到2023年的

436
00:12:39,683 --> 00:12:41,483
其实很多的自动驾驶的平台

437
00:12:41,483 --> 00:12:43,533
是用了各种各样的网络模型

438
00:12:43,533 --> 00:12:44,966
Bevnet了occupancy network

439
00:12:45,400 --> 00:12:47,400
还有很多相关的规划控制的算法

440
00:12:47,400 --> 00:12:48,200
去实现的

441
00:12:48,200 --> 00:12:50,533
那到了2024年的年初

442
00:12:50,533 --> 00:12:52,083
或者2023年的年底

443
00:12:52,083 --> 00:12:54,133
很多最新的端到端的算法

444
00:12:54,133 --> 00:12:55,050
就提出来了

445
00:12:55,166 --> 00:12:56,566
这样看这个视频觉得无聊

446
00:12:56,566 --> 00:12:57,133
但是没关系啊

447
00:12:57,133 --> 00:12:58,800
大家简单的了解一下就好了

448
00:12:58,800 --> 00:12:59,766
例如理想汽车

449
00:12:59,766 --> 00:13:02,166
就跟清华大学提出了一个drive VLM

450
00:13:02,166 --> 00:13:04,133
说实话因为要结合大模型

451
00:13:04,133 --> 00:13:05,650
就把一些图片

452
00:13:05,650 --> 00:13:06,766
作为一个大模型的输入

453
00:13:06,766 --> 00:13:08,966
然后大模型输出一些决策的内容

454
00:13:08,966 --> 00:13:09,283
然后

455
00:13:09,283 --> 00:13:11,683
最后翻译成planning的相关的工作

456
00:13:11,683 --> 00:13:12,483
那这种方式

457
00:13:12,483 --> 00:13:13,250
真的说实话

458
00:13:13,250 --> 00:13:13,966
我想用

459
00:13:13,966 --> 00:13:15,283
语言去控制一台车

460
00:13:15,483 --> 00:13:16,733
危险性还是很大的

461
00:13:17,050 --> 00:13:19,283
只能说他作为一个研究领域了

462
00:13:19,283 --> 00:13:20,250
是没有问题的

463
00:13:20,250 --> 00:13:21,400
所以说你可以看到

464
00:13:21,400 --> 00:13:22,450
我往哪里走

465
00:13:22,450 --> 00:13:23,333
我往前面走

466
00:13:23,333 --> 00:13:25,000
我往45度走还是怎么走

467
00:13:25,000 --> 00:13:26,450
其实他有很大的问题

468
00:13:26,450 --> 00:13:27,566
例如我往左偏一偏

469
00:13:27,566 --> 00:13:28,800
这里面前面有障碍物

470
00:13:28,800 --> 00:13:30,683
那我往左偏多少度

471
00:13:30,683 --> 00:13:32,083
所以基本上的这种方式

472
00:13:32,083 --> 00:13:33,000
只能说嗯

473
00:13:33,250 --> 00:13:34,850
学术上还是很有创新点

474
00:13:34,850 --> 00:13:37,133
对那接着我们看一下第二个内容呢

475
00:13:37,133 --> 00:13:39,966
就是地平线的VAD V2

476
00:13:39,966 --> 00:13:40,683
这篇文章

477
00:13:40,683 --> 00:13:43,050
也是用了一个planning的transformar模型

478
00:13:43,050 --> 00:13:44,933
把作为一个大模型进行输入

479
00:13:44,933 --> 00:13:46,600
然后呢进行一个输出的控制

480
00:13:46,600 --> 00:13:47,366
那这种方式

481
00:13:47,366 --> 00:13:49,000
其实更偏向于planning

482
00:13:49,050 --> 00:13:50,533
或者那个面向occupation planning

483
00:13:50,533 --> 00:13:51,083
推行paning

484
00:13:51,083 --> 00:13:52,650
就面向规划

485
00:13:52,650 --> 00:13:54,566
做了一个端到端的模型

486
00:13:54,566 --> 00:13:55,850
但是这种端到端的模型

487
00:13:55,850 --> 00:13:57,050
不一定是大模型

488
00:13:57,050 --> 00:13:57,483
这里面

489
00:13:57,483 --> 00:13:59,933
有非常多的一个panning的路径

490
00:13:59,933 --> 00:14:01,250
然后给到一个模型

491
00:14:01,250 --> 00:14:02,933
还有我们相关的数据

492
00:14:02,933 --> 00:14:04,400
把我们的图片的序列

493
00:14:04,400 --> 00:14:05,733
变成一系列的TOKEN

494
00:14:05,733 --> 00:14:07,533
然后呢结合我们规划的数据

495
00:14:07,683 --> 00:14:08,766
作为一个输出

496
00:14:08,766 --> 00:14:10,683
之后呢通过KL散度呢去对比

497
00:14:10,683 --> 00:14:13,083
选择一个比较好的一个控制的方式

498
00:14:13,083 --> 00:14:13,850
那这种方式

499
00:14:13,850 --> 00:14:15,283
其实现在来说

500
00:14:15,283 --> 00:14:16,683
还是比较好的

501
00:14:16,683 --> 00:14:17,883
zomi觉得这篇文章

502
00:14:18,250 --> 00:14:20,650
也值得大家去了解学习一下的

503
00:14:20,966 --> 00:14:22,166
那可以看到

504
00:14:22,166 --> 00:14:24,450
整个地平线的VAD V2呢

505
00:14:24,450 --> 00:14:26,333
这个是在仿真环境里面去做了

506
00:14:26,333 --> 00:14:26,966
仿真环境

507
00:14:26,966 --> 00:14:28,683
我们就叫做刚才讲了嘛

508
00:14:28,733 --> 00:14:31,166
也叫做我们的闭环的环境啊

509
00:14:32,250 --> 00:14:33,800
那在了第三篇文章

510
00:14:33,800 --> 00:14:35,650
就是Uni的ad

511
00:14:35,650 --> 00:14:37,083
2023年的CPVR的Paper

512
00:14:37,083 --> 00:14:38,200
paper这篇文章

513
00:14:38,200 --> 00:14:38,733
很特别的

514
00:14:38,733 --> 00:14:40,883
就是Uni的ad里面有四个模块

515
00:14:40,933 --> 00:14:41,650
一个模块

516
00:14:41,650 --> 00:14:42,133
我们看一下

517
00:14:42,133 --> 00:14:43,133
主要是下面这个图来

518
00:14:43,133 --> 00:14:43,966
其他其他图

519
00:14:43,966 --> 00:14:45,933
其实没什么卵用

520
00:14:46,166 --> 00:14:47,083
这里面有四个模块

521
00:14:47,083 --> 00:14:47,800
一个是特征提取

522
00:14:47,800 --> 00:14:48,400
感知模块

523
00:14:48,400 --> 00:14:49,000
预测模块

524
00:14:49,000 --> 00:14:49,883
规划模块

525
00:14:49,883 --> 00:14:52,200
那最重要的就是面向规划的

526
00:14:52,200 --> 00:14:54,650
它是个planningl为导向的网络模型

527
00:14:54,650 --> 00:14:55,483
单个网络模型

528
00:14:55,483 --> 00:14:56,250
就端到端的

529
00:14:56,250 --> 00:14:58,600
取代了传统的网络模型的起点的方式

530
00:14:58,850 --> 00:15:00,966
所以说大家也可以去看一下这篇文章

531
00:15:00,966 --> 00:15:01,483
里面

532
00:15:01,483 --> 00:15:03,766
就用了各种各样的全书本的结构呢

533
00:15:03,766 --> 00:15:05,366
做了一个面向panning的

534
00:15:05,366 --> 00:15:06,933
一个具体的网络模型

535
00:15:07,050 --> 00:15:10,050
那现在讲到的都是面向端到端的

536
00:15:10,050 --> 00:15:11,883
利用transformar结构的模型

537
00:15:11,883 --> 00:15:14,533
所以呢说为自己现在用大模型

538
00:15:14,533 --> 00:15:15,400
还未必

539
00:15:15,400 --> 00:15:16,883
有些厂商用了大模型

540
00:15:16,883 --> 00:15:17,933
但是很有可能

541
00:15:17,933 --> 00:15:19,533
大家只是用了transformar的结构

542
00:15:19,533 --> 00:15:21,200
或者用了大模型的结构

543
00:15:21,283 --> 00:15:23,966
并不是意义上的大模型

544
00:15:24,450 --> 00:15:26,166
那这我们还可以看到啊

545
00:15:26,166 --> 00:15:27,883
还有那个GenAD 

546
00:15:27,933 --> 00:15:30,800
现在呢连因为大模型是做生成式嘛

547
00:15:30,800 --> 00:15:32,533
或者transformar是做生成式的嘛

548
00:15:32,533 --> 00:15:34,283
所以现在连自动驾驶

549
00:15:34,283 --> 00:15:35,483
都搞生成式了

550
00:15:35,483 --> 00:15:36,966
但是上城市的自动驾驶呢

551
00:15:36,966 --> 00:15:37,933
靠不靠谱

552
00:15:38,000 --> 00:15:39,850
所以还是有待我们去研究的

553
00:15:39,850 --> 00:15:42,450
它到底是一个面向painting而去推选的

554
00:15:42,650 --> 00:15:44,133
还是面向规划

555
00:15:44,133 --> 00:15:46,400
去做一个导向的具体的网络模型

556
00:15:46,400 --> 00:15:48,533
还是直接生成我们的规划的路径

557
00:15:48,533 --> 00:15:49,366
所以说这方面

558
00:15:49,366 --> 00:15:51,650
也很值得我们去做一个研究的

559
00:15:51,650 --> 00:15:52,933
但大家可以看到

560
00:15:52,933 --> 00:15:54,733
除了特斯拉说他自己是一个端到端

561
00:15:54,733 --> 00:15:55,766
真正的大模型啊

562
00:15:55,800 --> 00:15:57,483
其他的行类的

563
00:15:57,533 --> 00:15:58,250
业界的方

564
00:15:58,250 --> 00:15:59,366
案呢都是在跟随

565
00:15:59,366 --> 00:16:00,250
或者在业界的

566
00:16:00,250 --> 00:16:02,650
或者在我们的学术界的前沿的区域

567
00:16:02,650 --> 00:16:04,133
做一个简单的探索

568
00:16:04,683 --> 00:16:04,933
当然

569
00:16:04,933 --> 00:16:08,250
还有包括英伟达最新发布的Hydra-MDP

570
00:16:08,250 --> 00:16:09,483
这个网络模型

571
00:16:09,850 --> 00:16:12,650
里面呢也不是一个端到端的大模型

572
00:16:12,650 --> 00:16:13,683
来去解决问题的

573
00:16:13,683 --> 00:16:15,133
而是像下面这个图啊

574
00:16:15,133 --> 00:16:15,933
它有个planning

575
00:16:15,933 --> 00:16:16,400
Perception啊

576
00:16:16,400 --> 00:16:19,883
simulation相关的几个大的模型

577
00:16:19,883 --> 00:16:20,966
然后串联起来

578
00:16:20,966 --> 00:16:23,400
然后实现一个规划和控制的

579
00:16:23,400 --> 00:16:24,366
那这种

580
00:16:24,366 --> 00:16:27,283
叫做啊Multi target learning

581
00:16:27,283 --> 00:16:28,850
还有multimodel planning啊

582
00:16:28,850 --> 00:16:30,566
大部分还是Im的学习的方式

583
00:16:30,566 --> 00:16:31,600
所以说可以看到

584
00:16:31,733 --> 00:16:34,683
真正意义上做到的端到端啊

585
00:16:34,683 --> 00:16:36,733
还并没有太多

586
00:16:36,733 --> 00:16:38,283
但是啊这篇文章

587
00:16:38,283 --> 00:16:39,283
其实已经很大程度的

588
00:16:39,283 --> 00:16:40,883
去解决了这个问题了

589
00:16:41,283 --> 00:16:41,883
那可以看到

590
00:16:41,883 --> 00:16:44,850
整个还是在业界的探索的过程当中

591
00:16:44,850 --> 00:16:45,200
因此

592
00:16:45,200 --> 00:16:48,366
我们简单的做一个技术上的小总结

593
00:16:48,533 --> 00:16:49,766
端到端的技术路线

594
00:16:49,766 --> 00:16:51,450
说实话从现在开始

595
00:16:51,450 --> 00:16:55,050
或者从2023年2024年这个时间段开始

596
00:16:55,050 --> 00:16:55,400
真正的

597
00:16:55,400 --> 00:16:57,566
大家已经不断的去做一个探索了

598
00:16:57,566 --> 00:17:00,283
但是真正落地的还是非常的少的

599
00:17:00,566 --> 00:17:00,966
所以说

600
00:17:00,966 --> 00:17:02,683
现在国内说自己是端到端的大模型

601
00:17:02,683 --> 00:17:03,766
绝对是吹牛逼的

602
00:17:03,933 --> 00:17:06,050
那我们可以看到简单的了解一下

603
00:17:06,050 --> 00:17:06,766
一部分

604
00:17:06,766 --> 00:17:07,966
就是从感知出发

605
00:17:07,966 --> 00:17:10,566
真正意义的端到端是从感知出发的

606
00:17:10,566 --> 00:17:11,683
那另外一部分

607
00:17:11,683 --> 00:17:14,200
就它是从规划问题去出发的

608
00:17:14,450 --> 00:17:15,766
前面先做一个融合的模型

609
00:17:15,766 --> 00:17:16,283
然后后面

610
00:17:16,283 --> 00:17:18,766
交给planning和Control相关的网络模型呢

611
00:17:18,766 --> 00:17:19,966
去做一个分离

612
00:17:19,966 --> 00:17:20,533
那这里面

613
00:17:20,533 --> 00:17:23,566
就用了好几种不同的方式了

614
00:17:26,000 --> 00:17:27,883
当然这篇视频啊

615
00:17:27,883 --> 00:17:29,483
特别的干货

616
00:17:29,483 --> 00:17:30,400
或者特别的无聊

617
00:17:30,400 --> 00:17:32,083
我们只是分析了端到端的

618
00:17:32,083 --> 00:17:34,850
大模型还做了一些简单的业界的吐槽

619
00:17:34,966 --> 00:17:35,483
实际上

620
00:17:35,483 --> 00:17:37,533
是没有去对比百度和特斯拉

621
00:17:37,533 --> 00:17:39,133
和国内一现在的情况的

622
00:17:39,133 --> 00:17:41,133
我们只是简单的技术分享啊

623
00:17:41,133 --> 00:17:42,083
所以这里面

624
00:17:42,083 --> 00:17:44,083
可能看我视频的人呢

625
00:17:44,366 --> 00:17:46,050
99%都是男的了

626
00:17:46,050 --> 00:17:47,133
同性交友

627
00:17:47,133 --> 00:17:48,000
看技术

628
00:17:48,600 --> 00:17:50,600
首先我们看一下两个思考点

629
00:17:50,600 --> 00:17:51,000
第一个

630
00:17:51,000 --> 00:17:52,450
就是端到端的感知

631
00:17:52,450 --> 00:17:54,000
或者端到端的角色规划

632
00:17:54,000 --> 00:17:56,083
都可以算作端到端的自动驾驶嘛

633
00:17:56,333 --> 00:17:57,800
呃首先呢肯定是的

634
00:17:57,800 --> 00:17:58,883
两种方案

635
00:17:58,883 --> 00:18:01,650
它其实都是属于端到端的方式

636
00:18:01,650 --> 00:18:03,533
只是业界的叫法呢不太一样

637
00:18:03,533 --> 00:18:04,200
那第二个问题

638
00:18:04,200 --> 00:18:05,766
就是端到端这种方式

639
00:18:05,766 --> 00:18:08,133
是对传统自动驾驶方式的推倒重来吗

640
00:18:08,283 --> 00:18:10,533
因为传统的自动驾驶的方式

641
00:18:10,533 --> 00:18:11,966
其实我们在之前已经讲过了

642
00:18:11,966 --> 00:18:12,966
它是一个级联的

643
00:18:12,966 --> 00:18:14,850
有多个系统来去串联起来的

644
00:18:14,850 --> 00:18:16,850
那包括特斯拉所在

645
00:18:17,050 --> 00:18:18,966
其实现在传统的自动驾驶技术

646
00:18:18,966 --> 00:18:19,933
并没有被抛弃

647
00:18:19,933 --> 00:18:22,000
而是从前台走向幕后啊

648
00:18:22,000 --> 00:18:23,850
也就是在一些位置情况下

649
00:18:23,850 --> 00:18:26,650
通过传统的一些自动驾驶系统

650
00:18:26,650 --> 00:18:28,733
来做一个接管的

